{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data\n",
    "\n",
    "In this notebook we perform the following steps:\n",
    "* Establish the first hour of the dataset\n",
    "* For the first month,\n",
    "  * Obtain a list of available stations by state\n",
    "  * Obtain temperature observations from weather stations in the MISO footprint\n",
    "    * Stations are organized into MISO regions by state boundaries\n",
    "    * Stations are predominantly clustered in population centers, making many observation redundant\n",
    "    * There are many lacunae in some stations\n",
    "  * Obtain the actual hourly MISO Load data and historical Medium-Term Load Forecasts (MTLF)\n",
    "  * Join Load and MTLF data with weather observations to complete the raw data\n",
    "  * Persist the data and demonstrate use of dataset wrapper class\n",
    "* Update the dataset to the current day\n",
    "* Identify and mitigate lacunae\n",
    "* Publish the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from weather_data import prevailing_time as est\n",
    "\n",
    "# beginning of MISO's historical records that include the southern region (zones 8-10)\n",
    "first_hour = est(2015, 2, 1, 0)\n",
    "# five hours weather data was lost for 2015-06-17\n",
    "# first_hour = est(2015, 7, 1, 0)\n",
    "\n",
    "# latest date with actual load data available is\n",
    "# l = date.today() - timedelta(days=2)\n",
    "# last_hour = est(l.year, l.month, l.day, 23)\n",
    "# instead, fix the date for repeatbility\n",
    "last_hour = est(2022, 3, 31, 23)\n",
    "\n",
    "test_split = last_hour - timedelta(days=364, hours=23)\n",
    "validation_split = test_split - timedelta(days=365)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Weather Data for Zones\n",
    "\n",
    "[Iowa State ASOS Network Downloads](https://mesonet.agron.iastate.edu/request/download.phtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_data import ASOS\n",
    "from pathlib import Path\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "\n",
    "zones = { 1 : {'MN': ['MSP',  # Minneapolis / St. Paul (STP)\n",
    "                      'RST',  # Rochester\n",
    "                      'DYT'], # Duluth\n",
    "               'ND': ['FAR',  # Fargo\n",
    "                      'BIS',  # Bismarck\n",
    "                      'GFK'], # Grand Forks\n",
    "               'SD': ['ABR'], # Aberdeen\n",
    "               'WI': ['LSE'], # La Crosse\n",
    "               'IL': ['SFY']  # Savanna \n",
    "              },\n",
    "          2 : {'WI': ['MSN', 'MKE', 'EAU', 'GRB'],\n",
    "               'MI': ['ANJ', 'SAW', 'IWD']},\n",
    "          3 : {'IA': ['DSM', 'CID', 'DVN', 'SUX', 'ALO', 'MCW']}\n",
    "        }\n",
    "\n",
    "def download_file_path(zone, state, station):\n",
    "    zone_data = f\"./data/zone_{zone}\"\n",
    "    Path(zone_data).mkdir(exist_ok=True)\n",
    "    return f'{zone_data}/{state}_{station}.parquet'\n",
    "\n",
    "asos = ASOS()\n",
    "def download_station(zone, state, station):\n",
    "    path = download_file_path(zone, state, station) \n",
    "    if isfile(path):\n",
    "        return pd.read_parquet(path)\n",
    "\n",
    "    station = asos.get_hourly_observations(station, first_hour, last_hour)\n",
    "    if station is None:\n",
    "        print(f'Retrieve {station} failed')\n",
    "        return None\n",
    "    station.to_parquet(path)\n",
    "    return station\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "def do_parallel(func, zones):\n",
    "    parallel = Parallel(n_jobs=cpu_count())\n",
    "    result = {}\n",
    "    for zone in zones:\n",
    "        stations = [(state, station) for state in zones[zone].keys() for station in zones[zone][state]]\n",
    "        result[zone] = pd.concat(parallel(delayed(func)(zone, state, station) for (state, station) in stations))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_results = do_parallel(download_station, zones)\n",
    "all_zones = pd.concat(zone_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "ABR     15\n",
       "ALO      9\n",
       "ANJ     34\n",
       "BIS     10\n",
       "CID     17\n",
       "DSM      1\n",
       "DVN     27\n",
       "DYT     59\n",
       "EAU      9\n",
       "FAR      9\n",
       "GFK      9\n",
       "GRB      7\n",
       "IWD    102\n",
       "LSE     30\n",
       "MCW     43\n",
       "MKE      4\n",
       "MSN      9\n",
       "MSP      4\n",
       "RST      9\n",
       "SAW      6\n",
       "SFY     98\n",
       "SUX     38\n",
       "Name: temp, dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated = all_zones[pd.isna(all_zones['observation_time'])].copy()\n",
    "f = interpolated.groupby([interpolated.index.date, 'station']).temp.count()\n",
    "f[f > 4].groupby(level='station').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "ALO    23\n",
       "BIS    11\n",
       "DSM     5\n",
       "EAU    24\n",
       "FAR    14\n",
       "GFK    10\n",
       "GRB    10\n",
       "MKE     8\n",
       "MSN     5\n",
       "MSP    10\n",
       "RST    20\n",
       "SAW     6\n",
       "Name: temp, dtype: int64"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f > 4].groupby(level='station').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones2 = { 1 : {'MN': ['MSP'],\n",
    "               'ND': ['BIS',  # Bismarck\n",
    "                      'GFK']  # Grand Forks\n",
    "              },\n",
    "          2 : {'WI': ['MSN', 'MKE', 'GRB'],\n",
    "               'MI': ['SAW']},\n",
    "          3 : {'IA': ['DSM']}\n",
    "        }\n",
    "\n",
    "results2 = do_parallel(download_station, zones2)\n",
    "all_zones2 = pd.concat(results2.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "BIS    11\n",
       "DSM     6\n",
       "GFK    11\n",
       "GRB    11\n",
       "MKE     9\n",
       "MSN     8\n",
       "MSP    11\n",
       "SAW     8\n",
       "Name: temp, dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolated = all_zones2[pd.isna(all_zones2['observation_time'])].copy()\n",
    "f = interpolated.groupby([interpolated.index.date, 'station']).temp.count()\n",
    "\n",
    "f[f > 4].groupby(level='station').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "BIS    10\n",
       "DSM     1\n",
       "GFK    12\n",
       "GRB     9\n",
       "MKE     4\n",
       "MSN     9\n",
       "MSP     4\n",
       "SAW     8\n",
       "Name: temp, dtype: int64"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f > 5].groupby(level='station').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Station for Each Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1_station = 'MSP'\n",
    "zone2_station = 'MKE'\n",
    "zone3_station = 'DSM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider weighted by population average temperature change across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station</th>\n",
       "      <th>BIS</th>\n",
       "      <th>GFK</th>\n",
       "      <th>MSP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-01 00:00:00-05:00</th>\n",
       "      <td>-2.02</td>\n",
       "      <td>-7.96</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 01:00:00-05:00</th>\n",
       "      <td>-2.02</td>\n",
       "      <td>-7.96</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 02:00:00-05:00</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-7.96</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 03:00:00-05:00</th>\n",
       "      <td>-4.00</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>19.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 04:00:00-05:00</th>\n",
       "      <td>-5.08</td>\n",
       "      <td>-9.94</td>\n",
       "      <td>19.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "station                     BIS   GFK    MSP\n",
       "hour                                        \n",
       "2015-02-01 00:00:00-05:00 -2.02 -7.96  23.00\n",
       "2015-02-01 01:00:00-05:00 -2.02 -7.96  23.00\n",
       "2015-02-01 02:00:00-05:00 -2.92 -7.96  21.02\n",
       "2015-02-01 03:00:00-05:00 -4.00 -9.04  19.04\n",
       "2015-02-01 04:00:00-05:00 -5.08 -9.94  19.04"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results2[1]\n",
    "df1 = df.pivot(columns='station', values='temp')\n",
    "df2 = df1.shift(periods=1)\n",
    "df2.iloc[0] = df2.iloc[1] #replace NaN\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000    2955\n",
       "-0.666667    1520\n",
       "-0.300000    1470\n",
       "-0.366667    1170\n",
       " 0.666667     957\n",
       "             ... \n",
       " 2.000000       1\n",
       " 0.800000       1\n",
       "-3.133333       1\n",
       " 1.666667       1\n",
       "-1.433333       1\n",
       "Length: 3492, dtype: int64"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone1 = (df1 - df2)\n",
    "zone1.mean(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Regional MTLF and Actual Load for each Observation Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_al_data import \n",
    "\n",
    "Path(\"./data/mtlf\").mkdir(exist_ok=True)\n",
    "forecast_output_dir = './data/mtlf'\n",
    "# the actuals aren't available until the next day\n",
    "actuals = get_daily_rf_al_df(first_hour, last_hour + timedelta(days=2.0), forecast_output_dir)\n",
    "actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize Features with Actuals\n",
    "\n",
    "There are a number of lacunae in the weather observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktime_idx(row): \n",
    "    return datetime.combine(row['Market Day'].date(), time(row['HourEnding'] - 1), timezone(timedelta(hours = -5)))\n",
    "\n",
    "actuals['time_idx'] = actuals.apply(mktime_idx, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.to_parquet('./data/actuals_mtlf.parquet')\n",
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.pivot(index='valid', columns='station', values='tmpf').dropna()\n",
    "data = p.join(actuals.set_index('time_idx'), how='inner')\n",
    "\n",
    "(n, _) = data.shape\n",
    "(num_weather_observations, _) = df.groupby('valid').count().shape\n",
    "(num_load_observations, _) = actuals.shape\n",
    "(num_weather_observations, num_load_observations, len(observation_hours), n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Business Hours\n",
    "\n",
    "Can we improve the performance of the model by introducing business hours into the feature set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay, BusinessHour\n",
    "\n",
    "federal_business_days = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "bh = BusinessHour()\n",
    "def is_biz_hour(d):\n",
    "    return federal_business_days.is_on_offset(d) and bh.is_on_offset(d)\n",
    "data['IsBusinessHour'] = data.index.to_series().apply(lambda d: 1 if is_biz_hour(d) else 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76a2b364cc0264c10adfbdfe3b5ba02e67c79fb140c1f3503657a619a8cf93d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks\n",
    "\n",
    "Here we return to our original sequence of historical load data without pivot\n",
    "the prior hours' data into features as was needed with the regression\n",
    "techniques.\n",
    "\n",
    "Moreover, we will not immediately employ the walkforward validation technique due to the time cost of daily retraining. Instead we will train the model to always predict 24 hours out. This simplifies our train/validation/test split as well.\n",
    "\n",
    "#### TODO predict 1 to 24 hours out\n",
    "\n",
    "We should train seperate models that predict each of the subsequent 24 hours. These 24 models can be trained independently of each other. This would allow us to train on data that is more recent in the sequence. The hour-ending 24 model will still be trained as above, but the other hours will have a smaller `delay`... but we need the hourly prediction for a particular hour... this approach would just give a \"good at `n` hours out\" model across the entire day. We could train 1-hour-out models, then do walk forward validation as before...feeding the hourly prediction into the sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSP</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>HourEnding</th>\n",
       "      <th>IsBusinessHour</th>\n",
       "      <th>LRZ1 MTLF (MWh)</th>\n",
       "      <th>LRZ1 ActualLoad (MWh)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-01 00:00:00-05:00</th>\n",
       "      <td>23.00</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11099</td>\n",
       "      <td>11337.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 01:00:00-05:00</th>\n",
       "      <td>21.02</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10829</td>\n",
       "      <td>11014.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 02:00:00-05:00</th>\n",
       "      <td>19.04</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10565</td>\n",
       "      <td>10795.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 03:00:00-05:00</th>\n",
       "      <td>19.04</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10468</td>\n",
       "      <td>10714.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-01 04:00:00-05:00</th>\n",
       "      <td>17.06</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10432</td>\n",
       "      <td>10700.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MSP  DayOfYear  HourEnding  IsBusinessHour  \\\n",
       "hour                                                                      \n",
       "2015-02-01 00:00:00-05:00  23.00         32           1               0   \n",
       "2015-02-01 01:00:00-05:00  21.02         32           2               0   \n",
       "2015-02-01 02:00:00-05:00  19.04         32           3               0   \n",
       "2015-02-01 03:00:00-05:00  19.04         32           4               0   \n",
       "2015-02-01 04:00:00-05:00  17.06         32           5               0   \n",
       "\n",
       "                           LRZ1 MTLF (MWh)  LRZ1 ActualLoad (MWh)  \n",
       "hour                                                               \n",
       "2015-02-01 00:00:00-05:00            11099               11337.89  \n",
       "2015-02-01 01:00:00-05:00            10829               11014.87  \n",
       "2015-02-01 02:00:00-05:00            10565               10795.37  \n",
       "2015-02-01 03:00:00-05:00            10468               10714.42  \n",
       "2015-02-01 04:00:00-05:00            10432               10700.09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import DataSet\n",
    "\n",
    "ds = DataSet('data/zone1.parquet', mtlf='LRZ1 MTLF (MWh)', actual='LRZ1 ActualLoad (MWh)')\n",
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are predicting 24 hours out, it is acceptable to incorporate the temperature data again, but we will need to normalize. We also will drop our categoricals for now. Can an RNN learn a good model for predicting tomorrow's load from just prior load and temperature sequences? Should we incorporate more temperature sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MSP', 'DayOfYear', 'HourEnding', 'IsBusinessHour', ds.actual]\n",
    "df = ds.data[features].copy()\n",
    "df[ds.actual] = df[ds.actual] / 100\n",
    "raw_data = df.to_numpy()\n",
    "load = ds.data[ds.actual].to_numpy()\n",
    "\n",
    "# 50/25/25 split. Probably need a different approach to validate over a year.\n",
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "\n",
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "#raw_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from validation import walkforward, Error\n",
    "from tensorflow import keras\n",
    "\n",
    "# our input sequence will be seven days of hourly observations\n",
    "sampling_rate = 1\n",
    "sequence_length = 72 #24*7\n",
    "\n",
    "# delay to ensure our predictions don't use intraday information\n",
    "# we start with 24 hours out\n",
    "delay = sampling_rate * (sequence_length + 24 - 1) \n",
    "\n",
    "batch_size = 32 # hyperparameter\n",
    "should_shuffle = True\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=load[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=should_shuffle,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples\n",
    ")\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=load[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=should_shuffle,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=load[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=should_shuffle,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, epochs=10):\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"naive_lstm.keras\", save_best_only=True)]\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "    history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks)\n",
    "    model = keras.models.load_model(\"naive_lstm.keras\")\n",
    "    print(f\"Test MAE: {model.evaluate(test_dataset)[1]:2f}\")\n",
    "    return history\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "979/979 [==============================] - 33s 23ms/step - loss: 125178136.0000 - mae: 11064.9092 - val_loss: 120327040.0000 - val_mae: 10854.8896\n",
      "Epoch 2/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 123751704.0000 - mae: 11000.2578 - val_loss: 118947848.0000 - val_mae: 10791.1748\n",
      "Epoch 3/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 122357720.0000 - mae: 10936.7275 - val_loss: 117582912.0000 - val_mae: 10727.7461\n",
      "Epoch 4/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 120975888.0000 - mae: 10873.3623 - val_loss: 116228528.0000 - val_mae: 10664.4346\n",
      "Epoch 5/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 119603536.0000 - mae: 10810.0635 - val_loss: 114883072.0000 - val_mae: 10601.1602\n",
      "Epoch 6/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 118239776.0000 - mae: 10746.8164 - val_loss: 113546016.0000 - val_mae: 10537.9121\n",
      "Epoch 7/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 116884584.0000 - mae: 10683.5713 - val_loss: 112217296.0000 - val_mae: 10474.6738\n",
      "Epoch 8/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 115537416.0000 - mae: 10620.3301 - val_loss: 110896560.0000 - val_mae: 10411.4492\n",
      "Epoch 9/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 114198304.0000 - mae: 10557.1025 - val_loss: 109584000.0000 - val_mae: 10348.2217\n",
      "Epoch 10/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 112867368.0000 - mae: 10493.8809 - val_loss: 108279512.0000 - val_mae: 10284.9971\n",
      "Epoch 11/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 111544392.0000 - mae: 10430.6572 - val_loss: 106983032.0000 - val_mae: 10221.7695\n",
      "Epoch 12/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 110229680.0000 - mae: 10367.4473 - val_loss: 105694600.0000 - val_mae: 10158.5566\n",
      "Epoch 13/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 108922856.0000 - mae: 10304.2285 - val_loss: 104414128.0000 - val_mae: 10095.3408\n",
      "Epoch 14/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 107624008.0000 - mae: 10241.0088 - val_loss: 103141816.0000 - val_mae: 10032.1250\n",
      "Epoch 15/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 106333280.0000 - mae: 10177.7959 - val_loss: 101877432.0000 - val_mae: 9968.9082\n",
      "Epoch 16/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 105050656.0000 - mae: 10114.5850 - val_loss: 100621328.0000 - val_mae: 9905.7041\n",
      "Epoch 17/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 103776072.0000 - mae: 10051.3799 - val_loss: 99373104.0000 - val_mae: 9842.5000\n",
      "Epoch 18/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 102509472.0000 - mae: 9988.1748 - val_loss: 98132992.0000 - val_mae: 9779.2959\n",
      "Epoch 19/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 101250880.0000 - mae: 9924.9736 - val_loss: 96900912.0000 - val_mae: 9716.0947\n",
      "Epoch 20/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 100000384.0000 - mae: 9861.7764 - val_loss: 95676792.0000 - val_mae: 9652.8945\n",
      "Epoch 21/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 98757840.0000 - mae: 9798.5693 - val_loss: 94460808.0000 - val_mae: 9589.7051\n",
      "Epoch 22/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 97523520.0000 - mae: 9735.3877 - val_loss: 93252704.0000 - val_mae: 9526.5117\n",
      "Epoch 23/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 96297240.0000 - mae: 9672.1982 - val_loss: 92052816.0000 - val_mae: 9463.3184\n",
      "Epoch 24/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 95078984.0000 - mae: 9609.0078 - val_loss: 90861176.0000 - val_mae: 9400.1455\n",
      "Epoch 25/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 93868680.0000 - mae: 9545.8252 - val_loss: 89677256.0000 - val_mae: 9336.9639\n",
      "Epoch 26/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 92666608.0000 - mae: 9482.6514 - val_loss: 88501544.0000 - val_mae: 9273.7900\n",
      "Epoch 27/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 91472376.0000 - mae: 9419.4727 - val_loss: 87333896.0000 - val_mae: 9210.6162\n",
      "Epoch 28/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 90286320.0000 - mae: 9356.3057 - val_loss: 86174024.0000 - val_mae: 9147.4443\n",
      "Epoch 29/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 89108168.0000 - mae: 9293.1348 - val_loss: 85022352.0000 - val_mae: 9084.2764\n",
      "Epoch 30/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 87938048.0000 - mae: 9229.9717 - val_loss: 83878664.0000 - val_mae: 9021.1055\n",
      "Epoch 31/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 86776120.0000 - mae: 9166.8027 - val_loss: 82743184.0000 - val_mae: 8957.9492\n",
      "Epoch 32/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 85622064.0000 - mae: 9103.6436 - val_loss: 81615704.0000 - val_mae: 8894.7900\n",
      "Epoch 33/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 84476208.0000 - mae: 9040.4883 - val_loss: 80496200.0000 - val_mae: 8831.6387\n",
      "Epoch 34/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 83338360.0000 - mae: 8977.3408 - val_loss: 79384744.0000 - val_mae: 8768.4883\n",
      "Epoch 35/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 82208656.0000 - mae: 8914.1953 - val_loss: 78281320.0000 - val_mae: 8705.3438\n",
      "Epoch 36/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 81086872.0000 - mae: 8851.0439 - val_loss: 77185880.0000 - val_mae: 8642.1953\n",
      "Epoch 37/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 79973024.0000 - mae: 8787.8975 - val_loss: 76098560.0000 - val_mae: 8579.0557\n",
      "Epoch 38/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 78867336.0000 - mae: 8724.7646 - val_loss: 75019272.0000 - val_mae: 8515.9209\n",
      "Epoch 39/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 77769696.0000 - mae: 8661.6436 - val_loss: 73947952.0000 - val_mae: 8452.7900\n",
      "Epoch 40/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 76680216.0000 - mae: 8598.5117 - val_loss: 72884872.0000 - val_mae: 8389.6660\n",
      "Epoch 41/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 75598584.0000 - mae: 8535.3887 - val_loss: 71829848.0000 - val_mae: 8326.5537\n",
      "Epoch 42/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 74525080.0000 - mae: 8472.2656 - val_loss: 70782536.0000 - val_mae: 8263.4258\n",
      "Epoch 43/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 73459504.0000 - mae: 8409.1445 - val_loss: 69743400.0000 - val_mae: 8200.3057\n",
      "Epoch 44/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 72402048.0000 - mae: 8346.0322 - val_loss: 68712408.0000 - val_mae: 8137.2085\n",
      "Epoch 45/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 71352704.0000 - mae: 8282.9268 - val_loss: 67689480.0000 - val_mae: 8074.1050\n",
      "Epoch 46/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 70311336.0000 - mae: 8219.8281 - val_loss: 66674556.0000 - val_mae: 8011.0020\n",
      "Epoch 47/50\n",
      "979/979 [==============================] - 21s 22ms/step - loss: 69278024.0000 - mae: 8156.7280 - val_loss: 65667480.0000 - val_mae: 7947.9028\n",
      "Epoch 48/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 68252624.0000 - mae: 8093.6328 - val_loss: 64668492.0000 - val_mae: 7884.8018\n",
      "Epoch 49/50\n",
      "979/979 [==============================] - 21s 21ms/step - loss: 67235400.0000 - mae: 8030.5288 - val_loss: 63677580.0000 - val_mae: 7821.7178\n",
      "Epoch 50/50\n",
      "979/979 [==============================] - 20s 21ms/step - loss: 66226012.0000 - mae: 7967.4512 - val_loss: 62694716.0000 - val_mae: 7758.6333\n",
      "486/486 [==============================] - 5s 7ms/step - loss: 64457252.0000 - mae: 7858.8154\n",
      "Test MAE: 7858.815430\n"
     ]
    }
   ],
   "source": [
    "x = layers.LSTM(64, unroll=True, return_sequences=True)(inputs)\n",
    "x = layers.LSTM(64, unroll=True)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "history = evaluate(model, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_evaluate(epochs=10):\n",
    "    model = keras.models.load_model(\"naive_lstm.keras\")\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(\"naive_lstm.keras\", save_best_only=True)]\n",
    "    history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, callbacks=callbacks)\n",
    "    model = keras.models.load_model(\"naive_lstm.keras\")\n",
    "    print(f\"Test MAE: {model.evaluate(test_dataset)[1]:2f}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "979/979 [==============================] - 39s 33ms/step - loss: 65224796.0000 - mae: 7904.3657 - val_loss: 61719864.0000 - val_mae: 7695.5508\n",
      "Epoch 2/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 64231476.0000 - mae: 7841.2803 - val_loss: 60752904.0000 - val_mae: 7632.4707\n",
      "Epoch 3/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 63246340.0000 - mae: 7778.2046 - val_loss: 59794132.0000 - val_mae: 7569.3994\n",
      "Epoch 4/100\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 62269196.0000 - mae: 7715.1431 - val_loss: 58843388.0000 - val_mae: 7506.3389\n",
      "Epoch 5/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 61300148.0000 - mae: 7652.0806 - val_loss: 57900648.0000 - val_mae: 7443.2739\n",
      "Epoch 6/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 60338960.0000 - mae: 7589.0195 - val_loss: 56965872.0000 - val_mae: 7380.2100\n",
      "Epoch 7/100\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 59385880.0000 - mae: 7525.9692 - val_loss: 56039176.0000 - val_mae: 7317.1553\n",
      "Epoch 8/100\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 58440852.0000 - mae: 7462.9111 - val_loss: 55120500.0000 - val_mae: 7254.1099\n",
      "Epoch 9/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 57503872.0000 - mae: 7399.8643 - val_loss: 54209804.0000 - val_mae: 7191.0693\n",
      "Epoch 10/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 56574860.0000 - mae: 7336.8320 - val_loss: 53307288.0000 - val_mae: 7128.0366\n",
      "Epoch 11/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 55653904.0000 - mae: 7273.7969 - val_loss: 52412684.0000 - val_mae: 7065.0068\n",
      "Epoch 12/100\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 54740992.0000 - mae: 7210.7734 - val_loss: 51526132.0000 - val_mae: 7001.9834\n",
      "Epoch 13/100\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 53836204.0000 - mae: 7147.7549 - val_loss: 50647624.0000 - val_mae: 6938.9692\n",
      "Epoch 14/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 52939416.0000 - mae: 7084.7407 - val_loss: 49777220.0000 - val_mae: 6875.9648\n",
      "Epoch 15/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 52050548.0000 - mae: 7021.7334 - val_loss: 48914716.0000 - val_mae: 6812.9580\n",
      "Epoch 16/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 51169748.0000 - mae: 6958.7324 - val_loss: 48060288.0000 - val_mae: 6749.9595\n",
      "Epoch 17/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 50297028.0000 - mae: 6895.7422 - val_loss: 47213884.0000 - val_mae: 6686.9644\n",
      "Epoch 18/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 49432212.0000 - mae: 6832.7451 - val_loss: 46375348.0000 - val_mae: 6623.9731\n",
      "Epoch 19/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 48575496.0000 - mae: 6769.7666 - val_loss: 45545068.0000 - val_mae: 6561.0005\n",
      "Epoch 20/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 47726768.0000 - mae: 6706.7852 - val_loss: 44722616.0000 - val_mae: 6498.0156\n",
      "Epoch 21/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 46886016.0000 - mae: 6643.8130 - val_loss: 43908176.0000 - val_mae: 6435.0454\n",
      "Epoch 22/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 46053368.0000 - mae: 6580.8525 - val_loss: 43101944.0000 - val_mae: 6372.0923\n",
      "Epoch 23/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 45228728.0000 - mae: 6517.8906 - val_loss: 42303516.0000 - val_mae: 6309.1304\n",
      "Epoch 24/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 44411924.0000 - mae: 6454.9346 - val_loss: 41513160.0000 - val_mae: 6246.1831\n",
      "Epoch 25/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 43603344.0000 - mae: 6391.9878 - val_loss: 40730856.0000 - val_mae: 6183.2461\n",
      "Epoch 26/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 42802748.0000 - mae: 6329.0537 - val_loss: 39956640.0000 - val_mae: 6120.3193\n",
      "Epoch 27/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 42010196.0000 - mae: 6266.1377 - val_loss: 39190320.0000 - val_mae: 6057.3892\n",
      "Epoch 28/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 41225576.0000 - mae: 6203.2070 - val_loss: 38432012.0000 - val_mae: 5994.4707\n",
      "Epoch 29/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 40448992.0000 - mae: 6140.2910 - val_loss: 37681772.0000 - val_mae: 5931.5635\n",
      "Epoch 30/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 39680524.0000 - mae: 6077.3940 - val_loss: 36939604.0000 - val_mae: 5868.6699\n",
      "Epoch 31/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 38919960.0000 - mae: 6014.4956 - val_loss: 36205344.0000 - val_mae: 5805.7764\n",
      "Epoch 32/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 38167392.0000 - mae: 5951.6030 - val_loss: 35479052.0000 - val_mae: 5742.8794\n",
      "Epoch 33/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 37422888.0000 - mae: 5888.7251 - val_loss: 34760888.0000 - val_mae: 5680.0151\n",
      "Epoch 34/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 36686472.0000 - mae: 5825.8647 - val_loss: 34050752.0000 - val_mae: 5617.1538\n",
      "Epoch 35/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 35957968.0000 - mae: 5763.0000 - val_loss: 33348528.0000 - val_mae: 5554.2964\n",
      "Epoch 36/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 35237480.0000 - mae: 5700.1445 - val_loss: 32654464.0000 - val_mae: 5491.4590\n",
      "Epoch 37/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 34525056.0000 - mae: 5637.3159 - val_loss: 31968168.0000 - val_mae: 5428.6108\n",
      "Epoch 38/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 33820552.0000 - mae: 5574.4722 - val_loss: 31290016.0000 - val_mae: 5365.7866\n",
      "Epoch 39/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 33124096.0000 - mae: 5511.6562 - val_loss: 30619732.0000 - val_mae: 5302.9658\n",
      "Epoch 40/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 32435598.0000 - mae: 5448.8306 - val_loss: 29957544.0000 - val_mae: 5240.1548\n",
      "Epoch 41/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 31755066.0000 - mae: 5386.0259 - val_loss: 29303280.0000 - val_mae: 5177.3530\n",
      "Epoch 42/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 31082606.0000 - mae: 5323.2358 - val_loss: 28657120.0000 - val_mae: 5114.5669\n",
      "Epoch 43/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 30418196.0000 - mae: 5260.4541 - val_loss: 28018954.0000 - val_mae: 5051.7939\n",
      "Epoch 44/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 29761800.0000 - mae: 5197.6919 - val_loss: 27388762.0000 - val_mae: 4989.0322\n",
      "Epoch 45/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 29113260.0000 - mae: 5134.9224 - val_loss: 26766508.0000 - val_mae: 4926.2715\n",
      "Epoch 46/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 28472792.0000 - mae: 5072.1787 - val_loss: 26152298.0000 - val_mae: 4863.5312\n",
      "Epoch 47/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 27840266.0000 - mae: 5009.4424 - val_loss: 25546104.0000 - val_mae: 4800.8105\n",
      "Epoch 48/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 27215868.0000 - mae: 4946.7246 - val_loss: 24947854.0000 - val_mae: 4738.0879\n",
      "Epoch 49/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 26599374.0000 - mae: 4884.0103 - val_loss: 24357608.0000 - val_mae: 4675.3901\n",
      "Epoch 50/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 25990932.0000 - mae: 4821.3193 - val_loss: 23775328.0000 - val_mae: 4612.6982\n",
      "Epoch 51/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 25390386.0000 - mae: 4758.6387 - val_loss: 23201128.0000 - val_mae: 4550.0308\n",
      "Epoch 52/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 24797878.0000 - mae: 4695.9644 - val_loss: 22634670.0000 - val_mae: 4487.3535\n",
      "Epoch 53/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 24213356.0000 - mae: 4633.3081 - val_loss: 22076410.0000 - val_mae: 4424.7139\n",
      "Epoch 54/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 23636780.0000 - mae: 4570.6689 - val_loss: 21526034.0000 - val_mae: 4362.0747\n",
      "Epoch 55/100\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 23068146.0000 - mae: 4508.0317 - val_loss: 20983520.0000 - val_mae: 4299.4404\n",
      "Epoch 56/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 22507554.0000 - mae: 4445.4155 - val_loss: 20449144.0000 - val_mae: 4236.8369\n",
      "Epoch 57/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 21954870.0000 - mae: 4382.8145 - val_loss: 19922672.0000 - val_mae: 4174.2485\n",
      "Epoch 58/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 21410184.0000 - mae: 4320.2275 - val_loss: 19404122.0000 - val_mae: 4111.6646\n",
      "Epoch 59/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 20873514.0000 - mae: 4257.6699 - val_loss: 18893658.0000 - val_mae: 4049.1162\n",
      "Epoch 60/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 20344818.0000 - mae: 4195.1187 - val_loss: 18391126.0000 - val_mae: 3986.5991\n",
      "Epoch 61/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 19824106.0000 - mae: 4132.5933 - val_loss: 17896620.0000 - val_mae: 3924.1128\n",
      "Epoch 62/100\n",
      "979/979 [==============================] - 31s 32ms/step - loss: 19311404.0000 - mae: 4070.0845 - val_loss: 17410058.0000 - val_mae: 3861.6589\n",
      "Epoch 63/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 18806686.0000 - mae: 4007.6057 - val_loss: 16931414.0000 - val_mae: 3799.2656\n",
      "Epoch 64/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 18309862.0000 - mae: 3945.1292 - val_loss: 16460712.0000 - val_mae: 3736.9346\n",
      "Epoch 65/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 17821004.0000 - mae: 3882.6812 - val_loss: 15997980.0000 - val_mae: 3674.7002\n",
      "Epoch 66/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 17340122.0000 - mae: 3820.2534 - val_loss: 15543136.0000 - val_mae: 3612.5396\n",
      "Epoch 67/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 16867224.0000 - mae: 3757.8516 - val_loss: 15096406.0000 - val_mae: 3550.5254\n",
      "Epoch 68/100\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 16402291.0000 - mae: 3695.4819 - val_loss: 14657570.0000 - val_mae: 3488.6943\n",
      "Epoch 69/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 15945213.0000 - mae: 3633.1494 - val_loss: 14226554.0000 - val_mae: 3426.9917\n",
      "Epoch 70/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 15496132.0000 - mae: 3570.8633 - val_loss: 13803544.0000 - val_mae: 3365.5012\n",
      "Epoch 71/100\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 15054987.0000 - mae: 3508.6448 - val_loss: 13388534.0000 - val_mae: 3304.2673\n",
      "Epoch 72/100\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 14621769.0000 - mae: 3446.4846 - val_loss: 12981279.0000 - val_mae: 3243.2661\n",
      "Epoch 73/100\n",
      "979/979 [==============================] - ETA: 0s - loss: 14196582.0000 - mae: 3384.4495"
     ]
    }
   ],
   "source": [
    "two_layer_history_2 = continue_evaluate(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "979/979 [==============================] - 35s 32ms/step - loss: 2762329.2500 - mae: 1324.8834 - val_loss: 2501932.2500 - val_mae: 1289.6077\n",
      "Epoch 2/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2756923.5000 - mae: 1323.9449 - val_loss: 2504910.7500 - val_mae: 1290.4341\n",
      "Epoch 3/50\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 2753159.5000 - mae: 1323.3875 - val_loss: 2508093.5000 - val_mae: 1291.3124\n",
      "Epoch 4/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2750556.7500 - mae: 1323.0702 - val_loss: 2511313.2500 - val_mae: 1292.1757\n",
      "Epoch 5/50\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 2748801.2500 - mae: 1322.9232 - val_loss: 2514267.0000 - val_mae: 1292.9673\n",
      "Epoch 6/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2747653.0000 - mae: 1322.8746 - val_loss: 2516886.2500 - val_mae: 1293.6660\n",
      "Epoch 7/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 2746924.0000 - mae: 1322.8937 - val_loss: 2519083.2500 - val_mae: 1294.2476\n",
      "Epoch 8/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2746445.0000 - mae: 1322.9469 - val_loss: 2520999.7500 - val_mae: 1294.7538\n",
      "Epoch 9/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2746130.0000 - mae: 1323.0079 - val_loss: 2522555.2500 - val_mae: 1295.1644\n",
      "Epoch 10/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745927.5000 - mae: 1323.0735 - val_loss: 2523884.7500 - val_mae: 1295.5139\n",
      "Epoch 11/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745791.7500 - mae: 1323.1338 - val_loss: 2524970.7500 - val_mae: 1295.7987\n",
      "Epoch 12/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745713.0000 - mae: 1323.1882 - val_loss: 2525834.5000 - val_mae: 1296.0249\n",
      "Epoch 13/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745656.2500 - mae: 1323.2341 - val_loss: 2526567.2500 - val_mae: 1296.2179\n",
      "Epoch 14/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745618.7500 - mae: 1323.2750 - val_loss: 2527155.5000 - val_mae: 1296.3716\n",
      "Epoch 15/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745595.7500 - mae: 1323.3085 - val_loss: 2527634.5000 - val_mae: 1296.4958\n",
      "Epoch 16/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745581.5000 - mae: 1323.3384 - val_loss: 2528104.7500 - val_mae: 1296.6205\n",
      "Epoch 17/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745571.0000 - mae: 1323.3595 - val_loss: 2528353.0000 - val_mae: 1296.6851\n",
      "Epoch 18/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745562.5000 - mae: 1323.3795 - val_loss: 2528651.7500 - val_mae: 1296.7627\n",
      "Epoch 19/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745560.2500 - mae: 1323.3964 - val_loss: 2528809.7500 - val_mae: 1296.8038\n",
      "Epoch 20/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2745554.7500 - mae: 1323.4082 - val_loss: 2528980.5000 - val_mae: 1296.8502\n",
      "Epoch 21/50\n",
      "979/979 [==============================] - 28s 29ms/step - loss: 2745554.5000 - mae: 1323.4200 - val_loss: 2529139.2500 - val_mae: 1296.8917\n",
      "Epoch 22/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745552.2500 - mae: 1323.4281 - val_loss: 2529246.7500 - val_mae: 1296.9198\n",
      "Epoch 23/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745552.7500 - mae: 1323.4337 - val_loss: 2529315.2500 - val_mae: 1296.9371\n",
      "Epoch 24/50\n",
      "979/979 [==============================] - 27s 27ms/step - loss: 2745554.7500 - mae: 1323.4391 - val_loss: 2529387.5000 - val_mae: 1296.9562\n",
      "Epoch 25/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745552.2500 - mae: 1323.4432 - val_loss: 2529478.2500 - val_mae: 1296.9802\n",
      "Epoch 26/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745550.0000 - mae: 1323.4459 - val_loss: 2529456.2500 - val_mae: 1296.9738\n",
      "Epoch 27/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.7500 - mae: 1323.4495 - val_loss: 2529532.7500 - val_mae: 1296.9941\n",
      "Epoch 28/50\n",
      "979/979 [==============================] - 27s 27ms/step - loss: 2745552.0000 - mae: 1323.4523 - val_loss: 2529479.0000 - val_mae: 1296.9812\n",
      "Epoch 29/50\n",
      "979/979 [==============================] - 27s 27ms/step - loss: 2745550.2500 - mae: 1323.4539 - val_loss: 2529602.7500 - val_mae: 1297.0138\n",
      "Epoch 30/50\n",
      "979/979 [==============================] - 27s 27ms/step - loss: 2745552.0000 - mae: 1323.4567 - val_loss: 2529607.7500 - val_mae: 1297.0148\n",
      "Epoch 31/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.7500 - mae: 1323.4584 - val_loss: 2529639.2500 - val_mae: 1297.0225\n",
      "Epoch 32/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.0000 - mae: 1323.4585 - val_loss: 2529656.5000 - val_mae: 1297.0267\n",
      "Epoch 33/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745548.0000 - mae: 1323.4590 - val_loss: 2529645.0000 - val_mae: 1297.0244\n",
      "Epoch 34/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745550.7500 - mae: 1323.4578 - val_loss: 2529652.7500 - val_mae: 1297.0258\n",
      "Epoch 35/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.0000 - mae: 1323.4603 - val_loss: 2529697.2500 - val_mae: 1297.0385\n",
      "Epoch 36/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.5000 - mae: 1323.4618 - val_loss: 2529695.7500 - val_mae: 1297.0376\n",
      "Epoch 37/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745552.7500 - mae: 1323.4622 - val_loss: 2529676.7500 - val_mae: 1297.0326\n",
      "Epoch 38/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745548.7500 - mae: 1323.4625 - val_loss: 2529723.0000 - val_mae: 1297.0455\n",
      "Epoch 39/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745551.7500 - mae: 1323.4626 - val_loss: 2529709.2500 - val_mae: 1297.0419\n",
      "Epoch 40/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745548.5000 - mae: 1323.4635 - val_loss: 2529722.7500 - val_mae: 1297.0442\n",
      "Epoch 41/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745552.0000 - mae: 1323.4628 - val_loss: 2529719.7500 - val_mae: 1297.0447\n",
      "Epoch 42/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745550.0000 - mae: 1323.4628 - val_loss: 2529664.7500 - val_mae: 1297.0288\n",
      "Epoch 43/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745553.0000 - mae: 1323.4631 - val_loss: 2529709.2500 - val_mae: 1297.0414\n",
      "Epoch 44/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745547.7500 - mae: 1323.4634 - val_loss: 2529729.2500 - val_mae: 1297.0474\n",
      "Epoch 45/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745550.7500 - mae: 1323.4618 - val_loss: 2529729.0000 - val_mae: 1297.0463\n",
      "Epoch 46/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745549.7500 - mae: 1323.4618 - val_loss: 2529684.0000 - val_mae: 1297.0352\n",
      "Epoch 47/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745550.7500 - mae: 1323.4634 - val_loss: 2529685.2500 - val_mae: 1297.0348\n",
      "Epoch 48/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745549.7500 - mae: 1323.4630 - val_loss: 2529704.7500 - val_mae: 1297.0408\n",
      "Epoch 49/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745548.7500 - mae: 1323.4629 - val_loss: 2529690.7500 - val_mae: 1297.0366\n",
      "Epoch 50/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2745550.7500 - mae: 1323.4618 - val_loss: 2529713.5000 - val_mae: 1297.0422\n",
      "486/486 [==============================] - 6s 10ms/step - loss: 2697904.7500 - mae: 1318.5011\n",
      "Test MAE: 1318.501099\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history5 = continue_evaluate(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "979/979 [==============================] - 35s 32ms/step - loss: 5589729.5000 - mae: 1913.5093 - val_loss: 4685331.5000 - val_mae: 1764.5638\n",
      "Epoch 2/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 5389443.5000 - mae: 1874.1122 - val_loss: 4510378.0000 - val_mae: 1728.2250\n",
      "Epoch 3/50\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 5196894.0000 - mae: 1836.0043 - val_loss: 4342994.0000 - val_mae: 1693.0957\n",
      "Epoch 4/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 5012089.0000 - mae: 1799.1465 - val_loss: 4183333.2500 - val_mae: 1659.2870\n",
      "Epoch 5/50\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 4834981.5000 - mae: 1763.7004 - val_loss: 4031318.7500 - val_mae: 1626.9216\n",
      "Epoch 6/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 4665585.0000 - mae: 1729.6680 - val_loss: 3887001.2500 - val_mae: 1596.0016\n",
      "Epoch 7/50\n",
      "979/979 [==============================] - 31s 31ms/step - loss: 4503937.5000 - mae: 1697.0873 - val_loss: 3750269.0000 - val_mae: 1566.4454\n",
      "Epoch 8/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 4349952.5000 - mae: 1665.8427 - val_loss: 3621208.0000 - val_mae: 1538.3531\n",
      "Epoch 9/50\n",
      "979/979 [==============================] - 30s 31ms/step - loss: 4203670.5000 - mae: 1636.0095 - val_loss: 3499628.5000 - val_mae: 1511.8531\n",
      "Epoch 10/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 4065010.0000 - mae: 1607.6125 - val_loss: 3385529.2500 - val_mae: 1486.7979\n",
      "Epoch 11/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3933875.7500 - mae: 1580.5702 - val_loss: 3278883.2500 - val_mae: 1463.1934\n",
      "Epoch 12/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 3810298.7500 - mae: 1554.8960 - val_loss: 3179720.0000 - val_mae: 1441.0796\n",
      "Epoch 13/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 3694235.5000 - mae: 1530.5585 - val_loss: 3087807.2500 - val_mae: 1420.4186\n",
      "Epoch 14/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3585546.5000 - mae: 1507.5795 - val_loss: 3003163.7500 - val_mae: 1401.3627\n",
      "Epoch 15/50\n",
      "979/979 [==============================] - 30s 30ms/step - loss: 3484376.5000 - mae: 1485.8870 - val_loss: 2925819.0000 - val_mae: 1383.8800\n",
      "Epoch 16/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3390626.0000 - mae: 1465.5111 - val_loss: 2855615.2500 - val_mae: 1368.0082\n",
      "Epoch 17/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3304073.0000 - mae: 1446.5143 - val_loss: 2792337.5000 - val_mae: 1353.6176\n",
      "Epoch 18/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3224703.5000 - mae: 1428.9829 - val_loss: 2735940.2500 - val_mae: 1340.7820\n",
      "Epoch 19/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3152485.0000 - mae: 1412.8545 - val_loss: 2686311.7500 - val_mae: 1329.5068\n",
      "Epoch 20/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3087230.0000 - mae: 1398.1249 - val_loss: 2643346.7500 - val_mae: 1319.7881\n",
      "Epoch 21/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 3028977.0000 - mae: 1384.8920 - val_loss: 2606684.2500 - val_mae: 1311.5616\n",
      "Epoch 22/50\n",
      "979/979 [==============================] - 29s 30ms/step - loss: 2977349.5000 - mae: 1373.0543 - val_loss: 2576216.2500 - val_mae: 1304.7836\n",
      "Epoch 23/50\n",
      "979/979 [==============================] - 29s 29ms/step - loss: 2932522.7500 - mae: 1362.7310 - val_loss: 2551685.7500 - val_mae: 1299.3411\n",
      "Epoch 24/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2893924.7500 - mae: 1353.8112 - val_loss: 2532419.5000 - val_mae: 1295.1619\n",
      "Epoch 25/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2860942.5000 - mae: 1346.3064 - val_loss: 2517962.5000 - val_mae: 1292.1003\n",
      "Epoch 26/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2833407.5000 - mae: 1340.1205 - val_loss: 2507980.2500 - val_mae: 1290.1006\n",
      "Epoch 27/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2811118.2500 - mae: 1335.1425 - val_loss: 2501861.7500 - val_mae: 1288.9255\n",
      "Epoch 28/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2793487.0000 - mae: 1331.2692 - val_loss: 2498923.5000 - val_mae: 1288.4591\n",
      "Epoch 29/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2779982.7500 - mae: 1328.3943 - val_loss: 2498393.2500 - val_mae: 1288.5006\n",
      "Epoch 30/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2769821.2500 - mae: 1326.3318 - val_loss: 2499606.5000 - val_mae: 1288.9246\n",
      "Epoch 31/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2762289.5000 - mae: 1324.8755 - val_loss: 2501942.7500 - val_mae: 1289.6105\n",
      "Epoch 32/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2756895.7500 - mae: 1323.9399 - val_loss: 2504954.5000 - val_mae: 1290.4457\n",
      "Epoch 33/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2753077.5000 - mae: 1323.3756 - val_loss: 2508208.0000 - val_mae: 1291.3428\n",
      "Epoch 34/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2750509.5000 - mae: 1323.0660 - val_loss: 2511356.5000 - val_mae: 1292.1866\n",
      "Epoch 35/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2748810.5000 - mae: 1322.9243 - val_loss: 2514250.7500 - val_mae: 1292.9623\n",
      "Epoch 36/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2747682.7500 - mae: 1322.8762 - val_loss: 2516822.5000 - val_mae: 1293.6495\n",
      "Epoch 37/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2746937.7500 - mae: 1322.8926 - val_loss: 2519044.2500 - val_mae: 1294.2379\n",
      "Epoch 38/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2746455.5000 - mae: 1322.9463 - val_loss: 2520965.5000 - val_mae: 1294.7440\n",
      "Epoch 39/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2746143.2500 - mae: 1323.0073 - val_loss: 2522499.5000 - val_mae: 1295.1497\n",
      "Epoch 40/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745932.5000 - mae: 1323.0693 - val_loss: 2523845.2500 - val_mae: 1295.5042\n",
      "Epoch 41/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745802.2500 - mae: 1323.1295 - val_loss: 2524928.5000 - val_mae: 1295.7882\n",
      "Epoch 42/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745714.0000 - mae: 1323.1848 - val_loss: 2525849.2500 - val_mae: 1296.0283\n",
      "Epoch 43/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745657.2500 - mae: 1323.2319 - val_loss: 2526508.7500 - val_mae: 1296.2028\n",
      "Epoch 44/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745625.2500 - mae: 1323.2726 - val_loss: 2527148.0000 - val_mae: 1296.3696\n",
      "Epoch 45/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745599.0000 - mae: 1323.3096 - val_loss: 2527668.5000 - val_mae: 1296.5059\n",
      "Epoch 46/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745580.2500 - mae: 1323.3368 - val_loss: 2528012.2500 - val_mae: 1296.5956\n",
      "Epoch 47/50\n",
      "979/979 [==============================] - 28s 28ms/step - loss: 2745573.7500 - mae: 1323.3621 - val_loss: 2528410.0000 - val_mae: 1296.6998\n",
      "Epoch 48/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745563.5000 - mae: 1323.3798 - val_loss: 2528625.7500 - val_mae: 1296.7572\n",
      "Epoch 49/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745555.7500 - mae: 1323.3967 - val_loss: 2528848.0000 - val_mae: 1296.8152\n",
      "Epoch 50/50\n",
      "979/979 [==============================] - 27s 28ms/step - loss: 2745559.2500 - mae: 1323.4111 - val_loss: 2529032.2500 - val_mae: 1296.8628\n",
      "486/486 [==============================] - 5s 9ms/step - loss: 2704913.2500 - mae: 1317.2195\n",
      "Test MAE: 1317.219482\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history4 = continue_evaluate(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "979/979 [==============================] - 16s 11ms/step - loss: 125128024.0000 - mae: 11062.6602 - val_loss: 120187896.0000 - val_mae: 10848.4775\n",
      "Epoch 2/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 123594264.0000 - mae: 10993.1123 - val_loss: 118783904.0000 - val_mae: 10783.5723\n",
      "Epoch 3/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 122186568.0000 - mae: 10928.8926 - val_loss: 117412752.0000 - val_mae: 10719.8105\n",
      "Epoch 4/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 120800992.0000 - mae: 10865.3242 - val_loss: 116056760.0000 - val_mae: 10656.3760\n",
      "Epoch 5/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 119428024.0000 - mae: 10801.9619 - val_loss: 114711528.0000 - val_mae: 10593.0635\n",
      "Epoch 6/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 118064688.0000 - mae: 10738.6689 - val_loss: 113375200.0000 - val_mae: 10529.8086\n",
      "Epoch 7/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 116710096.0000 - mae: 10675.4160 - val_loss: 112047504.0000 - val_mae: 10466.5586\n",
      "Epoch 8/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 115364096.0000 - mae: 10612.1689 - val_loss: 110727968.0000 - val_mae: 10403.3311\n",
      "Epoch 9/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 114025920.0000 - mae: 10548.9482 - val_loss: 109416600.0000 - val_mae: 10340.1094\n",
      "Epoch 10/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 112696064.0000 - mae: 10485.7070 - val_loss: 108113200.0000 - val_mae: 10276.8896\n",
      "Epoch 11/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 111374136.0000 - mae: 10422.4941 - val_loss: 106817944.0000 - val_mae: 10213.6846\n",
      "Epoch 12/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 110060368.0000 - mae: 10359.2773 - val_loss: 105530680.0000 - val_mae: 10150.4600\n",
      "Epoch 13/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 108754560.0000 - mae: 10296.0605 - val_loss: 104251576.0000 - val_mae: 10087.2559\n",
      "Epoch 14/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 107456880.0000 - mae: 10232.8389 - val_loss: 102980392.0000 - val_mae: 10024.0498\n",
      "Epoch 15/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 106167184.0000 - mae: 10169.6309 - val_loss: 101717296.0000 - val_mae: 9960.8408\n",
      "Epoch 16/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 104885632.0000 - mae: 10106.4150 - val_loss: 100462056.0000 - val_mae: 9897.6416\n",
      "Epoch 17/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 103612016.0000 - mae: 10043.2129 - val_loss: 99215352.0000 - val_mae: 9834.4492\n",
      "Epoch 18/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 102346544.0000 - mae: 9980.0166 - val_loss: 97976296.0000 - val_mae: 9771.2500\n",
      "Epoch 19/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 101089080.0000 - mae: 9916.8057 - val_loss: 96745360.0000 - val_mae: 9708.0645\n",
      "Epoch 20/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 99839624.0000 - mae: 9853.6152 - val_loss: 95522456.0000 - val_mae: 9644.8740\n",
      "Epoch 21/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 98598152.0000 - mae: 9790.4131 - val_loss: 94307680.0000 - val_mae: 9581.6836\n",
      "Epoch 22/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 97364888.0000 - mae: 9727.2324 - val_loss: 93100936.0000 - val_mae: 9518.5010\n",
      "Epoch 23/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 96139624.0000 - mae: 9664.0479 - val_loss: 91902208.0000 - val_mae: 9455.3242\n",
      "Epoch 24/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 94922272.0000 - mae: 9600.8545 - val_loss: 90711448.0000 - val_mae: 9392.1455\n",
      "Epoch 25/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 93713112.0000 - mae: 9537.6777 - val_loss: 89528784.0000 - val_mae: 9328.9668\n",
      "Epoch 26/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 92512008.0000 - mae: 9474.5020 - val_loss: 88354200.0000 - val_mae: 9265.7930\n",
      "Epoch 27/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 91318808.0000 - mae: 9411.3252 - val_loss: 87187608.0000 - val_mae: 9202.6328\n",
      "Epoch 28/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 90133744.0000 - mae: 9348.1475 - val_loss: 86029064.0000 - val_mae: 9139.4668\n",
      "Epoch 29/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 88956704.0000 - mae: 9284.9824 - val_loss: 84878512.0000 - val_mae: 9076.2988\n",
      "Epoch 30/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 87787760.0000 - mae: 9221.8164 - val_loss: 83736200.0000 - val_mae: 9013.1523\n",
      "Epoch 31/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 86626768.0000 - mae: 9158.6504 - val_loss: 82601632.0000 - val_mae: 8949.9863\n",
      "Epoch 32/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 85473736.0000 - mae: 9095.4893 - val_loss: 81475304.0000 - val_mae: 8886.8389\n",
      "Epoch 33/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 84328880.0000 - mae: 9032.3350 - val_loss: 80356904.0000 - val_mae: 8823.6904\n",
      "Epoch 34/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 83192088.0000 - mae: 8969.1777 - val_loss: 79246608.0000 - val_mae: 8760.5508\n",
      "Epoch 35/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 82063280.0000 - mae: 8906.0312 - val_loss: 78144400.0000 - val_mae: 8697.4062\n",
      "Epoch 36/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 80942664.0000 - mae: 8842.8945 - val_loss: 77050240.0000 - val_mae: 8634.2744\n",
      "Epoch 37/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 79829896.0000 - mae: 8779.7598 - val_loss: 75964144.0000 - val_mae: 8571.1465\n",
      "Epoch 38/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 78725320.0000 - mae: 8716.6123 - val_loss: 74885984.0000 - val_mae: 8508.0234\n",
      "Epoch 39/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 77628760.0000 - mae: 8653.4971 - val_loss: 73815872.0000 - val_mae: 8444.8965\n",
      "Epoch 40/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 76540192.0000 - mae: 8590.3594 - val_loss: 72753808.0000 - val_mae: 8381.7783\n",
      "Epoch 41/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 75459672.0000 - mae: 8527.2471 - val_loss: 71699800.0000 - val_mae: 8318.6631\n",
      "Epoch 42/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 74387120.0000 - mae: 8464.1201 - val_loss: 70653744.0000 - val_mae: 8255.5469\n",
      "Epoch 43/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 73322648.0000 - mae: 8401.0039 - val_loss: 69615904.0000 - val_mae: 8192.4473\n",
      "Epoch 44/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 72266232.0000 - mae: 8337.8926 - val_loss: 68585976.0000 - val_mae: 8129.3447\n",
      "Epoch 45/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 71217848.0000 - mae: 8274.7861 - val_loss: 67563952.0000 - val_mae: 8066.2363\n",
      "Epoch 46/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 70177472.0000 - mae: 8211.6797 - val_loss: 66550116.0000 - val_mae: 8003.1382\n",
      "Epoch 47/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 69145152.0000 - mae: 8148.5781 - val_loss: 65544276.0000 - val_mae: 7940.0518\n",
      "Epoch 48/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 68120920.0000 - mae: 8085.4863 - val_loss: 64546496.0000 - val_mae: 7876.9609\n",
      "Epoch 49/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 67104632.0000 - mae: 8022.3984 - val_loss: 63556720.0000 - val_mae: 7813.8799\n",
      "Epoch 50/50\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 66096428.0000 - mae: 7959.3164 - val_loss: 62574896.0000 - val_mae: 7750.8052\n",
      "486/486 [==============================] - 2s 3ms/step - loss: 64329388.0000 - mae: 7850.6753\n",
      "Test MAE: 7850.675293\n"
     ]
    }
   ],
   "source": [
    "x = layers.LSTM(64, unroll=True)(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "history = evaluate(model, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history5.history[\"mae\"]\n",
    "val_loss = history5.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 17s 119ms/step - loss: 125989480.0000 - mae: 11101.4648 - val_loss: 121780832.0000 - val_mae: 10921.6025\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125881392.0000 - mae: 11096.5947 - val_loss: 121692072.0000 - val_mae: 10917.5371\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125791344.0000 - mae: 11092.5342 - val_loss: 121603464.0000 - val_mae: 10913.4795\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125701304.0000 - mae: 11088.4717 - val_loss: 121514880.0000 - val_mae: 10909.4238\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125611320.0000 - mae: 11084.4209 - val_loss: 121426344.0000 - val_mae: 10905.3604\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125521328.0000 - mae: 11080.3555 - val_loss: 121337840.0000 - val_mae: 10901.3057\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125431424.0000 - mae: 11076.3018 - val_loss: 121249336.0000 - val_mae: 10897.2432\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 15s 119ms/step - loss: 125341512.0000 - mae: 11072.2412 - val_loss: 121160952.0000 - val_mae: 10893.1865\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125251664.0000 - mae: 11068.1836 - val_loss: 121072496.0000 - val_mae: 10889.1279\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125161824.0000 - mae: 11064.1260 - val_loss: 120984120.0000 - val_mae: 10885.0654\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 123315360.0000 - mae: 10982.9365\n",
      "Test MAE: 10982.936523\n"
     ]
    }
   ],
   "source": [
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs)\n",
    "x = layers.LSTM(32)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 17s 119ms/step - loss: 125989480.0000 - mae: 11101.4648 - val_loss: 121780832.0000 - val_mae: 10921.6025\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125881392.0000 - mae: 11096.5947 - val_loss: 121692072.0000 - val_mae: 10917.5371\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125791344.0000 - mae: 11092.5342 - val_loss: 121603464.0000 - val_mae: 10913.4795\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125701304.0000 - mae: 11088.4717 - val_loss: 121514880.0000 - val_mae: 10909.4238\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125611320.0000 - mae: 11084.4209 - val_loss: 121426344.0000 - val_mae: 10905.3604\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125521328.0000 - mae: 11080.3555 - val_loss: 121337840.0000 - val_mae: 10901.3057\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125431424.0000 - mae: 11076.3018 - val_loss: 121249336.0000 - val_mae: 10897.2432\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 15s 119ms/step - loss: 125341512.0000 - mae: 11072.2412 - val_loss: 121160952.0000 - val_mae: 10893.1865\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125251664.0000 - mae: 11068.1836 - val_loss: 121072496.0000 - val_mae: 10889.1279\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 14s 117ms/step - loss: 125161824.0000 - mae: 11064.1260 - val_loss: 120984120.0000 - val_mae: 10885.0654\n",
      "61/61 [==============================] - 3s 41ms/step - loss: 123315360.0000 - mae: 10982.9365\n",
      "Test MAE: 10982.936523\n"
     ]
    }
   ],
   "source": [
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs)\n",
    "x = layers.LSTM(32)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 4s 29ms/step - loss: 126039144.0000 - mae: 11103.6895 - val_loss: 121801320.0000 - val_mae: 10922.5420\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125897816.0000 - mae: 11097.3350 - val_loss: 121706424.0000 - val_mae: 10918.1963\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125805664.0000 - mae: 11093.1807 - val_loss: 121617432.0000 - val_mae: 10914.1221\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125715456.0000 - mae: 11089.1152 - val_loss: 121528840.0000 - val_mae: 10910.0596\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125625504.0000 - mae: 11085.0566 - val_loss: 121440312.0000 - val_mae: 10906.0029\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125535544.0000 - mae: 11081.0029 - val_loss: 121351784.0000 - val_mae: 10901.9453\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125445576.0000 - mae: 11076.9385 - val_loss: 121263280.0000 - val_mae: 10897.8838\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125355696.0000 - mae: 11072.8799 - val_loss: 121174856.0000 - val_mae: 10893.8252\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125265808.0000 - mae: 11068.8213 - val_loss: 121086464.0000 - val_mae: 10889.7656\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 125175944.0000 - mae: 11064.7656 - val_loss: 120998048.0000 - val_mae: 10885.7070\n",
      "61/61 [==============================] - 1s 9ms/step - loss: 123329416.0000 - mae: 10983.5752\n",
      "Test MAE: 10983.575195\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = layers.LSTM(32, return_sequences=True)(inputs)\n",
    "x = layers.LSTM(64, return_sequences=True)(inputs)\n",
    "x = layers.LSTM(32)(inputs)\n",
    "#x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "#x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "evaluate(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea54240020e07c96210ab594155946643681c2705be142acda2fae782468806d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mml-i7LNY0oE')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data\n",
    "\n",
    "In this notebook we perform the following steps:\n",
    "* Establish the first hour of the dataset\n",
    "* For the first month,\n",
    "  * Obtain a list of available stations by state\n",
    "  * Obtain temperature observations from weather stations in the MISO footprint\n",
    "    * Stations are organized into MISO regions by state boundaries\n",
    "    * Stations are predominantly clustered in population centers, making many observation redundant\n",
    "    * There are many lacunae in some stations\n",
    "  * Obtain the actual hourly MISO Load data and historical Medium-Term Load Forecasts (MTLF)\n",
    "  * Join Load and MTLF data with weather observations to complete the raw data\n",
    "  * Persist the data and demonstrate use of dataset wrapper class\n",
    "* Update the dataset to the current day\n",
    "* Identify and mitigate lacunae\n",
    "* Publish the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "def est(yyyy, mm, dd, hh):\n",
    "    return datetime(yyyy, mm, dd, hh, tzinfo=timezone(timedelta(hours=-5)))\n",
    "\n",
    "# beginning of MISO's historical records that include the southern region (zones 8-10)\n",
    "first_hour = est(2015, 2, 1, 0)\n",
    "\n",
    "# latest date with actual load data available is\n",
    "# l = date.today() - timedelta(days=2)\n",
    "# last_hour = est(l.year, l.month, l.day, 23)\n",
    "# instead, fix the date for repeatbility\n",
    "last_hour = est(2022, 4, 22, 23)\n",
    "\n",
    "test_split = last_hour - timedelta(days=364, hours=23)\n",
    "validation_split = test_split - timedelta(days=365)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Weather Data for Zones\n",
    "\n",
    "[Iowa State ASOS Network Downloads](https://mesonet.agron.iastate.edu/request/download.phtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_data import get_station_df\n",
    "from pathlib import Path\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "\n",
    "zones = { 1 : {'MN': ['MSP',  # Minneapolis / St. Paul (STP)\n",
    "                      'RST',  # Rochester\n",
    "                      'DLH'], # Duluth\n",
    "               'ND': ['FAR',  # Fargo\n",
    "                      'BIS',  # Bismarck\n",
    "                      'GFK'], # Grand Forks\n",
    "               'SD': ['ABR'], # Aberdeen\n",
    "               'WI': ['LSE'], # La Crosse\n",
    "               'IL': ['SFY']  # Savanna \n",
    "              },\n",
    "          2 : {'WI': ['MSN', 'MKE', 'EAU', 'GRB'],\n",
    "               'MI': ['ANJ', 'SAW', 'IWD']},\n",
    "          3 : {'IA': ['DSM', 'CID', 'DVN', 'SUX', 'ALO', 'MCW']}\n",
    "        }\n",
    "\n",
    "def download_file_path(zone, state, station):\n",
    "    zone_data = f\"./data/zone_{zone}\"\n",
    "    Path(zone_data).mkdir(exist_ok=True)\n",
    "    return f'{zone_data}/{state}_{station}.parquet'\n",
    "\n",
    "def download_station(zone, state, station):\n",
    "    path = download_file_path(zone, state, station) \n",
    "    if isfile(path):\n",
    "        return pd.read_parquet(path)\n",
    "\n",
    "    station = get_station_df(station, first_hour, last_hour)\n",
    "    if station is None:\n",
    "        print(f'Retrieve {station} failed')\n",
    "        return None\n",
    "    return station.to_parquet(path)\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "def do_parallel(func):\n",
    "    parallel = Parallel(n_jobs=cpu_count())\n",
    "    result = {}\n",
    "    for zone in zones:\n",
    "        stations = [(state, station) for state in zones[zone].keys() for station in zones[zone][state]]\n",
    "        result[zone] = parallel(delayed(func)(zone, state, station) for (state, station) in stations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = do_parallel(download_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained raw weather observations at various intervals, usually 15 minutes, but there is a lot of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "for zone in zones:\n",
    "  for state in zones[zone]:\n",
    "      for station in zones[zone][state]:\n",
    "        raw_df = pd.concat([raw_df, pd.read_parquet(download_file_path(zone, state, station))])\n",
    "raw_df[raw_df['tmpf'] == 'M'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[raw_df['tmpf'] == 'M'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a temperature observation for each hour, since that is how the MISO MTLF is reported. Our initial approach will be to simply drop all missing observations, then choose the observation that is closest in time to the top of the hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dates = pd.date_range(start = first_hour, end = last_hour)\n",
    "observation_hours = [d.replace(hour = h) for d in observation_dates for h in range(0, 24)]\n",
    "\n",
    "def build_hourly_df(zone, state, station):\n",
    "    w = pd.read_parquet(download_file_path(zone, state, station))\n",
    "    df = w[w['tmpf'] != 'M'].copy()\n",
    "    df['valid'] = pd.to_datetime(df['valid'], utc=True)\n",
    "    numeric_cols = ['tmpf', 'lat', 'lon']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, axis=1)\n",
    "    df = df.drop(columns=['feel'])\n",
    "    idx = df.drop_duplicates('valid').set_index('valid').index.get_indexer(observation_hours, method='nearest')\n",
    "    print(pd.Series(idx).value_counts())\n",
    "    df = df.iloc[idx]\n",
    "    df.loc[: , 'valid'] = df['valid'].dt.round(freq='H')\n",
    "    return df.drop_duplicates('valid') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = do_parallel(build_hourly_df)\n",
    "zonal_weather_data = {}\n",
    "for zone in zones:\n",
    "    zonal_weather_data[zone] = pd.concat(dfs[zone], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in pd.unique(zonal_weather_data[1]['station']):\n",
    "    df = zonal_weather_data[1]\n",
    "    count = df[df['station'] == station].shape[0]\n",
    "    print(f'{station} observation count {count}')\n",
    "print(f'Required observations {len(observation_hours)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df[df['station'] == 'DLH'], pd.DataFrame(observation_hours, columns=['Hours']), how='right', left_on='valid', right_on='Hours')\n",
    "merged[merged['station'].isna()]['Hours'].apply(lambda h: h.date).value_counts()[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are entire days missing in the observations. We need to try to obtain observations from nearby stations to fill in the lacunae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from weather_data import get_stations, get_session\n",
    "duluth = pd.read_parquet(download_file_path(1, 'MN', 'DLH'))\n",
    "stations_raw = get_stations('MN', 2015, get_session('https://'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_MN_df = pd.DataFrame(stations_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_MN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort stations MN by closest to another station\n",
    "from geopy import distance\n",
    "dlh = stations_MN_df[stations_MN_df['sid'] == 'DLH'].iloc[0]['latlon']\n",
    "stations_MN_df['distance_from_DLH'] = stations_MN_df['latlon'].apply(lambda c: distance.distance(dlh, c).mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>sname</th>\n",
       "      <th>time_domain</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>climate_site</th>\n",
       "      <th>wfo</th>\n",
       "      <th>tzname</th>\n",
       "      <th>ncdc81</th>\n",
       "      <th>ncei91</th>\n",
       "      <th>ugc_county</th>\n",
       "      <th>ugc_zone</th>\n",
       "      <th>county</th>\n",
       "      <th>sid</th>\n",
       "      <th>latlon</th>\n",
       "      <th>distance_from_DLH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>435.0</td>\n",
       "      <td>DULUTH</td>\n",
       "      <td>(1948-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN2248</td>\n",
       "      <td>DLH</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USW00014913</td>\n",
       "      <td>USW00014913</td>\n",
       "      <td>MNC137</td>\n",
       "      <td>MNZ037</td>\n",
       "      <td>St Louis</td>\n",
       "      <td>DLH</td>\n",
       "      <td>(46.8421, -92.1936)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>186.0</td>\n",
       "      <td>DULUTH (SKY HARB</td>\n",
       "      <td>(1976-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN2248</td>\n",
       "      <td>DLH</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00478349</td>\n",
       "      <td>USC00478349</td>\n",
       "      <td>MNC137</td>\n",
       "      <td>MNZ037</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>DYT</td>\n",
       "      <td>(46.7219, -92.0434)</td>\n",
       "      <td>10.942301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>390.0</td>\n",
       "      <td>CLOQUET</td>\n",
       "      <td>(1991-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN1630</td>\n",
       "      <td>DLH</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00211630</td>\n",
       "      <td>USC00211630</td>\n",
       "      <td>MNC017</td>\n",
       "      <td>MNZ037</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>COQ</td>\n",
       "      <td>(46.7011, -92.5036)</td>\n",
       "      <td>17.644290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>328.0</td>\n",
       "      <td>TWO HARBORS</td>\n",
       "      <td>(1991-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN8419</td>\n",
       "      <td>DLH</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00218419</td>\n",
       "      <td>USC00218419</td>\n",
       "      <td>MNC075</td>\n",
       "      <td>MNZ020</td>\n",
       "      <td>Lake</td>\n",
       "      <td>TWM</td>\n",
       "      <td>(47.0492, -91.745)</td>\n",
       "      <td>25.593478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>328.0</td>\n",
       "      <td>MOOSE LAKE</td>\n",
       "      <td>(1976-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN1074</td>\n",
       "      <td>DLH</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00215598</td>\n",
       "      <td>USC00215598</td>\n",
       "      <td>MNC017</td>\n",
       "      <td>MNZ037</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>MZH</td>\n",
       "      <td>(46.4186, -92.8048)</td>\n",
       "      <td>41.249770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>441.0</td>\n",
       "      <td>JACKSON MUNI</td>\n",
       "      <td>(1991-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN9033</td>\n",
       "      <td>FSD</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00214453</td>\n",
       "      <td>USC00214453</td>\n",
       "      <td>MNC063</td>\n",
       "      <td>MNZ900</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>MJQ</td>\n",
       "      <td>(43.65, -94.9866)</td>\n",
       "      <td>259.105153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>495.0</td>\n",
       "      <td>Slayton</td>\n",
       "      <td>(2005-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN8323</td>\n",
       "      <td>FSD</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00214534</td>\n",
       "      <td>USC00214534</td>\n",
       "      <td>MNC101</td>\n",
       "      <td>MNZ900</td>\n",
       "      <td>Murray</td>\n",
       "      <td>DVP</td>\n",
       "      <td>(43.9868, -95.7826)</td>\n",
       "      <td>263.293540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>480.0</td>\n",
       "      <td>WORTHINGTON</td>\n",
       "      <td>(1972-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN9033</td>\n",
       "      <td>FSD</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00219170</td>\n",
       "      <td>USC00219170</td>\n",
       "      <td>MNC105</td>\n",
       "      <td>MNZ900</td>\n",
       "      <td>Nobles</td>\n",
       "      <td>OTG</td>\n",
       "      <td>(43.6551, -95.5792)</td>\n",
       "      <td>275.100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>529.0</td>\n",
       "      <td>PIPESTONE</td>\n",
       "      <td>(1991-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN6565</td>\n",
       "      <td>FSD</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00216565</td>\n",
       "      <td>USC00216565</td>\n",
       "      <td>MNC117</td>\n",
       "      <td>MNZ900</td>\n",
       "      <td>Pipestone</td>\n",
       "      <td>PQN</td>\n",
       "      <td>(43.9821, -96.3004)</td>\n",
       "      <td>280.838537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>436.0</td>\n",
       "      <td>Luverne</td>\n",
       "      <td>(2005-Now)</td>\n",
       "      <td>MN</td>\n",
       "      <td>US</td>\n",
       "      <td>MN6565</td>\n",
       "      <td>FSD</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>USC00214937</td>\n",
       "      <td>USC00137147</td>\n",
       "      <td>MNC133</td>\n",
       "      <td>MNZ900</td>\n",
       "      <td>Rock</td>\n",
       "      <td>LYV</td>\n",
       "      <td>(43.6212, -96.2158)</td>\n",
       "      <td>296.553043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     elevation             sname time_domain state country climate_site  wfo  \\\n",
       "19       435.0            DULUTH  (1948-Now)    MN      US       MN2248  DLH   \n",
       "20       186.0  DULUTH (SKY HARB  (1976-Now)    MN      US       MN2248  DLH   \n",
       "13       390.0           CLOQUET  (1991-Now)    MN      US       MN1630  DLH   \n",
       "91       328.0       TWO HARBORS  (1991-Now)    MN      US       MN8419  DLH   \n",
       "59       328.0        MOOSE LAKE  (1976-Now)    MN      US       MN1074  DLH   \n",
       "..         ...               ...         ...   ...     ...          ...  ...   \n",
       "40       441.0      JACKSON MUNI  (1991-Now)    MN      US       MN9033  FSD   \n",
       "81       495.0           Slayton  (2005-Now)    MN      US       MN8323  FSD   \n",
       "101      480.0       WORTHINGTON  (1972-Now)    MN      US       MN9033  FSD   \n",
       "70       529.0         PIPESTONE  (1991-Now)    MN      US       MN6565  FSD   \n",
       "45       436.0           Luverne  (2005-Now)    MN      US       MN6565  FSD   \n",
       "\n",
       "              tzname       ncdc81       ncei91 ugc_county ugc_zone     county  \\\n",
       "19   America/Chicago  USW00014913  USW00014913     MNC137   MNZ037   St Louis   \n",
       "20   America/Chicago  USC00478349  USC00478349     MNC137   MNZ037  St. Louis   \n",
       "13   America/Chicago  USC00211630  USC00211630     MNC017   MNZ037  St. Louis   \n",
       "91   America/Chicago  USC00218419  USC00218419     MNC075   MNZ020       Lake   \n",
       "59   America/Chicago  USC00215598  USC00215598     MNC017   MNZ037    Carlton   \n",
       "..               ...          ...          ...        ...      ...        ...   \n",
       "40   America/Chicago  USC00214453  USC00214453     MNC063   MNZ900    Jackson   \n",
       "81   America/Chicago  USC00214534  USC00214534     MNC101   MNZ900     Murray   \n",
       "101  America/Chicago  USC00219170  USC00219170     MNC105   MNZ900     Nobles   \n",
       "70   America/Chicago  USC00216565  USC00216565     MNC117   MNZ900  Pipestone   \n",
       "45   America/Chicago  USC00214937  USC00137147     MNC133   MNZ900       Rock   \n",
       "\n",
       "     sid               latlon  distance_from_DLH  \n",
       "19   DLH  (46.8421, -92.1936)           0.000000  \n",
       "20   DYT  (46.7219, -92.0434)          10.942301  \n",
       "13   COQ  (46.7011, -92.5036)          17.644290  \n",
       "91   TWM   (47.0492, -91.745)          25.593478  \n",
       "59   MZH  (46.4186, -92.8048)          41.249770  \n",
       "..   ...                  ...                ...  \n",
       "40   MJQ    (43.65, -94.9866)         259.105153  \n",
       "81   DVP  (43.9868, -95.7826)         263.293540  \n",
       "101  OTG  (43.6551, -95.5792)         275.100258  \n",
       "70   PQN  (43.9821, -96.3004)         280.838537  \n",
       "45   LYV  (43.6212, -96.2158)         296.553043  \n",
       "\n",
       "[102 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_MN_df.sort_values(['distance_from_DLH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlh_latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.distance(dlh_latlon, dlh_latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Regional MTLF and Actual Load for each Observation Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_al_data import \n",
    "\n",
    "Path(\"./data/mtlf\").mkdir(exist_ok=True)\n",
    "forecast_output_dir = './data/mtlf'\n",
    "# the actuals aren't available until the next day\n",
    "actuals = get_daily_rf_al_df(first_hour, last_hour + timedelta(days=2.0), forecast_output_dir)\n",
    "actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize Features with Actuals\n",
    "\n",
    "There are a number of lacunae in the weather observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktime_idx(row): \n",
    "    return datetime.combine(row['Market Day'].date(), time(row['HourEnding'] - 1), timezone(timedelta(hours = -5)))\n",
    "\n",
    "actuals['time_idx'] = actuals.apply(mktime_idx, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.to_parquet('./data/actuals_mtlf.parquet')\n",
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.pivot(index='valid', columns='station', values='tmpf').dropna()\n",
    "data = p.join(actuals.set_index('time_idx'), how='inner')\n",
    "\n",
    "(n, _) = data.shape\n",
    "(num_weather_observations, _) = df.groupby('valid').count().shape\n",
    "(num_load_observations, _) = actuals.shape\n",
    "(num_weather_observations, num_load_observations, len(observation_hours), n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Business Hours\n",
    "\n",
    "Can we improve the performance of the model by introducing business hours into the feature set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay, BusinessHour\n",
    "\n",
    "federal_business_days = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "bh = BusinessHour()\n",
    "def is_biz_hour(d):\n",
    "    return federal_business_days.is_on_offset(d) and bh.is_on_offset(d)\n",
    "data['IsBusinessHour'] = data.index.to_series().apply(lambda d: 1 if is_biz_hour(d) else 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76a2b364cc0264c10adfbdfe3b5ba02e67c79fb140c1f3503657a619a8cf93d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

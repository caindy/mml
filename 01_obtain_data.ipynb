{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data\n",
    "\n",
    "In this notebook we perform the following steps:\n",
    "* Establish the first hour of the dataset\n",
    "* For the first month,\n",
    "  * Obtain a list of available stations by state\n",
    "  * Obtain temperature observations from weather stations in the MISO footprint\n",
    "    * Stations are organized into MISO regions by state boundaries\n",
    "    * Stations are predominantly clustered in population centers, making many observation redundant\n",
    "    * There are many lacunae in some stations\n",
    "  * Obtain the actual hourly MISO Load data and historical Medium-Term Load Forecasts (MTLF)\n",
    "  * Join Load and MTLF data with weather observations to complete the raw data\n",
    "  * Persist the data and demonstrate use of dataset wrapper class\n",
    "* Update the dataset to the current day\n",
    "* Identify and mitigate lacunae\n",
    "* Publish the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from weather_data import prevailing_time as est\n",
    "\n",
    "# beginning of MISO's historical records that include the southern region (zones 8-10)\n",
    "# five hours weather data was lost for 2015-06-17\n",
    "first_hour = est(2015, 6, 18, 4)\n",
    "\n",
    "# latest date with actual load data available is\n",
    "# l = date.today() - timedelta(days=2)\n",
    "# last_hour = est(l.year, l.month, l.day, 23)\n",
    "# instead, fix the date for repeatbility\n",
    "last_hour = est(2022, 4, 22, 23)\n",
    "\n",
    "test_split = last_hour - timedelta(days=364, hours=23)\n",
    "validation_split = test_split - timedelta(days=365)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Weather Data for Zones\n",
    "\n",
    "[Iowa State ASOS Network Downloads](https://mesonet.agron.iastate.edu/request/download.phtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_data import get_station_df\n",
    "from pathlib import Path\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "\n",
    "zones = { 1 : {'MN': ['MSP',  # Minneapolis / St. Paul (STP)\n",
    "                      'RST',  # Rochester\n",
    "                      'DYT'], # Duluth\n",
    "               'ND': ['FAR',  # Fargo\n",
    "                      'BIS',  # Bismarck\n",
    "                      'GFK'], # Grand Forks\n",
    "               'SD': ['ABR'], # Aberdeen\n",
    "               'WI': ['LSE'], # La Crosse\n",
    "               'IL': ['SFY']  # Savanna \n",
    "              },\n",
    "          2 : {'WI': ['MSN', 'MKE', 'EAU', 'GRB'],\n",
    "               'MI': ['ANJ', 'SAW', 'IWD']},\n",
    "          3 : {'IA': ['DSM', 'CID', 'DVN', 'SUX', 'ALO', 'MCW']}\n",
    "        }\n",
    "\n",
    "def download_file_path(zone, state, station):\n",
    "    zone_data = f\"./data/zone_{zone}\"\n",
    "    Path(zone_data).mkdir(exist_ok=True)\n",
    "    return f'{zone_data}/{state}_{station}.parquet'\n",
    "\n",
    "def download_station(zone, state, station):\n",
    "    path = download_file_path(zone, state, station) \n",
    "    if isfile(path):\n",
    "        return pd.read_parquet(path)\n",
    "\n",
    "    station = get_station_df(station, first_hour, last_hour)\n",
    "    if station is None:\n",
    "        print(f'Retrieve {station} failed')\n",
    "        return None\n",
    "    return station.to_parquet(path)\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "def do_parallel(func):\n",
    "    parallel = Parallel(n_jobs=cpu_count())\n",
    "    result = {}\n",
    "    for zone in zones:\n",
    "        stations = [(state, station) for state in zones[zone].keys() for station in zones[zone][state]]\n",
    "        result[zone] = parallel(delayed(func)(zone, state, station) for (state, station) in stations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = do_parallel(download_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained raw weather observations at various intervals, usually 15 minutes, but there is a lot of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>feel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:00</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:15</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:20</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:35</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 18:00</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     station             valid tmpf      lat      lon feel\n",
       "9559     MSP  2016-04-30 17:00    M  44.8854 -93.2313    M\n",
       "9560     MSP  2016-04-30 17:15    M  44.8854 -93.2313    M\n",
       "9561     MSP  2016-04-30 17:20    M  44.8854 -93.2313    M\n",
       "9562     MSP  2016-04-30 17:35    M  44.8854 -93.2313    M\n",
       "9564     MSP  2016-04-30 18:00    M  44.8854 -93.2313    M"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "for zone in zones:\n",
    "  for state in zones[zone]:\n",
    "      for station in zones[zone][state]:\n",
    "        raw_df = pd.concat([raw_df, pd.read_parquet(download_file_path(zone, state, station))])\n",
    "raw_df[raw_df['tmpf'] == 'M'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880084, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['tmpf'] == 'M'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>feel</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 00:53</td>\n",
       "      <td>68.00</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>68.00</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 01:53</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:27</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:48</td>\n",
       "      <td>66.20</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.20</td>\n",
       "      <td>66.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:53</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station             valid   tmpf      lat      lon   feel   temp\n",
       "0     MSP  2015-06-18 00:53  68.00  44.8854 -93.2313  68.00  68.00\n",
       "1     MSP  2015-06-18 01:53  66.92  44.8854 -93.2313  66.92  66.92\n",
       "2     MSP  2015-06-18 02:27  66.92  44.8854 -93.2313  66.92  66.92\n",
       "3     MSP  2015-06-18 02:48  66.20  44.8854 -93.2313  66.20  66.20\n",
       "4     MSP  2015-06-18 02:53  66.92  44.8854 -93.2313  66.92  66.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['temp'] = pd.to_numeric(raw_df['tmpf'], errors='coerce')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880084, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_temps = raw_df[pd.isna(raw_df['temp'])]\n",
    "missing_temps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['temp_backfill'] = raw_df['temp'].fillna(method='backfill', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9627182, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_temps = raw_df[pd.isna(raw_df['temp_backfill'])]\n",
    "missing_temps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-01 00:00:00     0.0\n",
       "2020-01-01 00:15:00     0.5\n",
       "2020-01-01 00:30:00     1.0\n",
       "2020-01-01 00:45:00     1.5\n",
       "2020-01-01 01:00:00     2.5\n",
       "                       ... \n",
       "2020-01-01 23:00:00    90.5\n",
       "2020-01-01 23:15:00    91.5\n",
       "2020-01-01 23:30:00    92.5\n",
       "2020-01-01 23:45:00    93.5\n",
       "2020-01-02 00:00:00    94.5\n",
       "Freq: 15T, Length: 97, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(range(24*4+1), index=pd.date_range('2020-01-01', '2020-01-02', freq='15min'))\n",
    "s.rolling(window='1H').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>tmpf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station                      time   tmpf\n",
       "valid                                                             \n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08\n",
       "2016-06-18 23:55:00+00:00     DLH 2016-06-18 23:55:00+00:00  78.08"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_data import ASOS\n",
    "asos = ASOS()\n",
    "dlh_df = asos.get_station_df('DLH', est(2016, 6, 16, 0), est(2016, 6, 18, 23))\n",
    "dlh_df[12:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>observing_station</th>\n",
       "      <th>observation_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-17 01:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>69.08</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 00:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 03:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>59.00</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 02:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 06:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.94</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 05:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 07:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.04</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 06:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 08:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.04</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 07:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 09:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.04</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 08:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 12:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>57.92</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 11:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 14:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>66.02</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 13:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 15:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.06</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 14:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 16:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>69.08</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 15:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 18:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>75.92</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 17:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 20:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>77.00</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 19:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 21:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>73.94</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 20:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 22:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.06</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 21:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 23:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.06</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 22:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 02:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>68.00</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 01:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 03:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>66.02</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 02:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 04:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>64.04</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 03:55:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station   tmpf observing_station  \\\n",
       "idx                                                          \n",
       "2016-06-17 01:00:00+00:00     DLH  69.08               DLH   \n",
       "2016-06-17 03:00:00+00:00     DLH  59.00               DLH   \n",
       "2016-06-17 06:00:00+00:00     DLH  55.94               DLH   \n",
       "2016-06-17 07:00:00+00:00     DLH  55.04               DLH   \n",
       "2016-06-17 08:00:00+00:00     DLH  55.04               DLH   \n",
       "2016-06-17 09:00:00+00:00     DLH  55.04               DLH   \n",
       "2016-06-17 12:00:00+00:00     DLH  57.92               DLH   \n",
       "2016-06-17 14:00:00+00:00     DLH  66.02               DLH   \n",
       "2016-06-17 15:00:00+00:00     DLH  71.06               DLH   \n",
       "2016-06-17 16:00:00+00:00     DLH  69.08               DLH   \n",
       "2016-06-17 18:00:00+00:00     DLH  75.92               DLH   \n",
       "2016-06-17 20:00:00+00:00     DLH  77.00               DLH   \n",
       "2016-06-17 21:00:00+00:00     DLH  73.94               DLH   \n",
       "2016-06-17 22:00:00+00:00     DLH  71.06               DLH   \n",
       "2016-06-17 23:00:00+00:00     DLH  71.06               DLH   \n",
       "2016-06-18 02:00:00+00:00     DLH  68.00               DLH   \n",
       "2016-06-18 03:00:00+00:00     DLH  66.02               DLH   \n",
       "2016-06-18 04:00:00+00:00     DLH  64.04               DLH   \n",
       "\n",
       "                                   observation_time  \n",
       "idx                                                  \n",
       "2016-06-17 01:00:00+00:00 2016-06-17 00:55:00+00:00  \n",
       "2016-06-17 03:00:00+00:00 2016-06-17 02:55:00+00:00  \n",
       "2016-06-17 06:00:00+00:00 2016-06-17 05:55:00+00:00  \n",
       "2016-06-17 07:00:00+00:00 2016-06-17 06:55:00+00:00  \n",
       "2016-06-17 08:00:00+00:00 2016-06-17 07:55:00+00:00  \n",
       "2016-06-17 09:00:00+00:00 2016-06-17 08:55:00+00:00  \n",
       "2016-06-17 12:00:00+00:00 2016-06-17 11:55:00+00:00  \n",
       "2016-06-17 14:00:00+00:00 2016-06-17 13:55:00+00:00  \n",
       "2016-06-17 15:00:00+00:00 2016-06-17 14:55:00+00:00  \n",
       "2016-06-17 16:00:00+00:00 2016-06-17 15:55:00+00:00  \n",
       "2016-06-17 18:00:00+00:00 2016-06-17 17:55:00+00:00  \n",
       "2016-06-17 20:00:00+00:00 2016-06-17 19:55:00+00:00  \n",
       "2016-06-17 21:00:00+00:00 2016-06-17 20:55:00+00:00  \n",
       "2016-06-17 22:00:00+00:00 2016-06-17 21:55:00+00:00  \n",
       "2016-06-17 23:00:00+00:00 2016-06-17 22:55:00+00:00  \n",
       "2016-06-18 02:00:00+00:00 2016-06-18 01:55:00+00:00  \n",
       "2016-06-18 03:00:00+00:00 2016-06-18 02:55:00+00:00  \n",
       "2016-06-18 04:00:00+00:00 2016-06-18 03:55:00+00:00  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_data import ASOS\n",
    "asos = ASOS()\n",
    "dlh_df = asos.get_station_df('DLH', est(2016, 6, 16, 0), est(2016, 6, 18, 23))\n",
    "dlh_df[12:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>observing_station</th>\n",
       "      <th>observation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-16 17:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>65.445070</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 16:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 18:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>67.296671</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 19:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>69.237073</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 19:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 20:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>70.668092</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 21:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.960000</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 20:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 22:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.960282</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 22:05:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 23:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.965029</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-16 22:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 00:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>71.485115</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 00:05:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 01:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>66.639983</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 01:05:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 02:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>62.992230</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 01:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 03:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 02:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 04:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>57.553357</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 03:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 05:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>54.750489</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 05:05:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 06:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.068027</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 07:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.040000</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 06:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 08:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.040000</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 07:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 09:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.040000</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 08:55:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-17 10:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>55.195329</td>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-17 10:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station       tmpf observing_station  \\\n",
       "2016-06-16 17:00:00+00:00     DLH  65.445070               DLH   \n",
       "2016-06-16 18:00:00+00:00     DLH  67.296671               DLH   \n",
       "2016-06-16 19:00:00+00:00     DLH  69.237073               DLH   \n",
       "2016-06-16 20:00:00+00:00     DLH  70.668092               DLH   \n",
       "2016-06-16 21:00:00+00:00     DLH  71.960000               DLH   \n",
       "2016-06-16 22:00:00+00:00     DLH  71.960282               DLH   \n",
       "2016-06-16 23:00:00+00:00     DLH  71.965029               DLH   \n",
       "2016-06-17 00:00:00+00:00     DLH  71.485115               DLH   \n",
       "2016-06-17 01:00:00+00:00     DLH  66.639983               DLH   \n",
       "2016-06-17 02:00:00+00:00     DLH  62.992230               DLH   \n",
       "2016-06-17 03:00:00+00:00     DLH  59.000000               DLH   \n",
       "2016-06-17 04:00:00+00:00     DLH  57.553357               DLH   \n",
       "2016-06-17 05:00:00+00:00     DLH  54.750489               DLH   \n",
       "2016-06-17 06:00:00+00:00     DLH  55.068027               DLH   \n",
       "2016-06-17 07:00:00+00:00     DLH  55.040000               DLH   \n",
       "2016-06-17 08:00:00+00:00     DLH  55.040000               DLH   \n",
       "2016-06-17 09:00:00+00:00     DLH  55.040000               DLH   \n",
       "2016-06-17 10:00:00+00:00     DLH  55.195329               DLH   \n",
       "\n",
       "                                   observation_time  \n",
       "2016-06-16 17:00:00+00:00 2016-06-16 16:55:00+00:00  \n",
       "2016-06-16 18:00:00+00:00 2016-06-16 18:00:00+00:00  \n",
       "2016-06-16 19:00:00+00:00 2016-06-16 19:00:00+00:00  \n",
       "2016-06-16 20:00:00+00:00 2016-06-16 20:00:00+00:00  \n",
       "2016-06-16 21:00:00+00:00 2016-06-16 20:55:00+00:00  \n",
       "2016-06-16 22:00:00+00:00 2016-06-16 22:05:00+00:00  \n",
       "2016-06-16 23:00:00+00:00 2016-06-16 22:55:00+00:00  \n",
       "2016-06-17 00:00:00+00:00 2016-06-17 00:05:00+00:00  \n",
       "2016-06-17 01:00:00+00:00 2016-06-17 01:05:00+00:00  \n",
       "2016-06-17 02:00:00+00:00 2016-06-17 01:55:00+00:00  \n",
       "2016-06-17 03:00:00+00:00 2016-06-17 02:55:00+00:00  \n",
       "2016-06-17 04:00:00+00:00 2016-06-17 03:55:00+00:00  \n",
       "2016-06-17 05:00:00+00:00 2016-06-17 05:05:00+00:00  \n",
       "2016-06-17 06:00:00+00:00 2016-06-17 06:00:00+00:00  \n",
       "2016-06-17 07:00:00+00:00 2016-06-17 06:55:00+00:00  \n",
       "2016-06-17 08:00:00+00:00 2016-06-17 07:55:00+00:00  \n",
       "2016-06-17 09:00:00+00:00 2016-06-17 08:55:00+00:00  \n",
       "2016-06-17 10:00:00+00:00 2016-06-17 10:00:00+00:00  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_data import ASOS\n",
    "asos = ASOS()\n",
    "dlh_df = asos.get_station_df('DLH', est(2016, 6, 16, 0), est(2016, 6, 18, 23))\n",
    "dlh_df[12:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>observation_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observing_station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLH</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYT</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUW</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   station  tmpf  observation_time\n",
       "observing_station                                 \n",
       "DLH                     49    49                49\n",
       "DYT                     17    17                17\n",
       "SUW                      1     1                 1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlh_df.groupby('observing_station').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>observing_station</th>\n",
       "      <th>observation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-18 00:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 01:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 02:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 03:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 04:00:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station  tmpf observing_station observation_time\n",
       "2016-06-18 00:00:00+00:00     DLH   NaN               NaN              NaT\n",
       "2016-06-19 01:00:00+00:00     DLH   NaN               NaN              NaT\n",
       "2016-06-19 02:00:00+00:00     DLH   NaN               NaN              NaT\n",
       "2016-06-19 03:00:00+00:00     DLH   NaN               NaN              NaT\n",
       "2016-06-19 04:00:00+00:00     DLH   NaN               NaN              NaT"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlh_df[pd.isna(dlh_df['tmpf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 1, 0, 0, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=68400)))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est(2020, 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            valid\n",
       "2016-06-16  4        49.640\n",
       "            5        50.000\n",
       "            6        50.504\n",
       "            7        50.000\n",
       "            8        50.000\n",
       "            9        51.080\n",
       "            10       51.620\n",
       "            11       51.980\n",
       "            12       50.660\n",
       "            13       51.530\n",
       "            14       55.904\n",
       "            15       55.400\n",
       "            16       56.480\n",
       "            17       55.400\n",
       "            18       57.200\n",
       "            19       61.400\n",
       "            20       71.960\n",
       "            21       64.400\n",
       "            22       67.415\n",
       "            23       71.060\n",
       "2016-06-17  0        63.050\n",
       "            1        59.450\n",
       "            2        59.000\n",
       "            3        55.400\n",
       "            4        55.400\n",
       "            5        55.280\n",
       "            6        55.040\n",
       "            7        55.040\n",
       "            8        55.040\n",
       "            9        53.600\n",
       "            10       53.600\n",
       "            11       57.920\n",
       "            12       53.600\n",
       "            13       58.055\n",
       "            14       71.060\n",
       "            15       69.080\n",
       "            16       66.110\n",
       "            17       75.920\n",
       "            18       59.900\n",
       "            19       77.000\n",
       "            20       73.940\n",
       "            21       66.200\n",
       "            22       71.060\n",
       "            23       64.400\n",
       "Name: tmpf, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlh_df.groupby([dlh_df.index.date, dlh_df.index.hour]).tmpf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using DYT 2016-06-16 04:14:00+00:00 48.2 for DLH 2016-06-16 04:05:00+00:00\n",
      "using DYT 2016-06-16 05:54:00+00:00 48.2 for DLH 2016-06-16 06:00:00+00:00\n",
      "using DYT 2016-06-16 07:54:00+00:00 50.0 for DLH 2016-06-16 08:00:00+00:00\n",
      "using DYT 2016-06-16 12:34:00+00:00 50.0 for DLH 2016-06-16 12:30:00+00:00\n",
      "using DYT 2016-06-16 12:53:00+00:00 50.0 for DLH 2016-06-16 12:50:00+00:00\n",
      "using DYT 2016-06-16 12:53:00+00:00 50.0 for DLH 2016-06-16 13:00:00+00:00\n",
      "using DYT 2016-06-16 13:14:00+00:00 50.0 for DLH 2016-06-16 13:20:00+00:00\n",
      "using DYT 2016-06-16 15:33:00+00:00 55.4 for DLH 2016-06-16 15:30:00+00:00\n",
      "using DYT 2016-06-16 15:54:00+00:00 55.4 for DLH 2016-06-16 15:50:00+00:00\n",
      "using DYT 2016-06-16 15:54:00+00:00 55.4 for DLH 2016-06-16 16:00:00+00:00\n",
      "using DYT 2016-06-16 16:14:00+00:00 55.4 for DLH 2016-06-16 16:15:00+00:00\n",
      "using DYT 2016-06-16 16:33:00+00:00 57.2 for DLH 2016-06-16 16:30:00+00:00\n",
      "using DYT 2016-06-16 16:54:00+00:00 57.2 for DLH 2016-06-16 16:45:00+00:00\n",
      "using DYT 2016-06-16 16:54:00+00:00 57.2 for DLH 2016-06-16 16:55:00+00:00\n",
      "using DYT 2016-06-16 17:14:00+00:00 55.4 for DLH 2016-06-16 17:10:00+00:00\n",
      "using DYT 2016-06-16 17:54:00+00:00 55.4 for DLH 2016-06-16 17:50:00+00:00\n",
      "using DYT 2016-06-16 17:54:00+00:00 55.4 for DLH 2016-06-16 18:00:00+00:00\n",
      "using DYT 2016-06-16 18:13:00+00:00 57.2 for DLH 2016-06-16 18:15:00+00:00\n",
      "using DYT 2016-06-16 18:33:00+00:00 59.0 for DLH 2016-06-16 18:40:00+00:00\n",
      "using DYT 2016-06-16 18:54:00+00:00 60.8 for DLH 2016-06-16 19:00:00+00:00\n",
      "using DYT 2016-06-16 19:14:00+00:00 60.8 for DLH 2016-06-16 19:20:00+00:00\n",
      "using DYT 2016-06-16 19:54:00+00:00 62.6 for DLH 2016-06-16 19:55:00+00:00\n",
      "using DYT 2016-06-16 21:34:00+00:00 64.4 for DLH 2016-06-16 21:25:00+00:00\n",
      "using DYT 2016-06-16 21:34:00+00:00 64.4 for DLH 2016-06-16 21:30:00+00:00\n",
      "using DYT 2016-06-16 21:53:00+00:00 64.4 for DLH 2016-06-16 21:55:00+00:00\n",
      "using DYT 2016-06-16 22:14:00+00:00 66.2 for DLH 2016-06-16 22:05:00+00:00\n",
      "using DYT 2016-06-16 22:14:00+00:00 66.2 for DLH 2016-06-16 22:15:00+00:00\n",
      "using DYT 2016-06-16 22:34:00+00:00 66.2 for DLH 2016-06-16 22:30:00+00:00\n",
      "using DYT 2016-06-17 00:14:00+00:00 64.4 for DLH 2016-06-17 00:05:00+00:00\n",
      "using DYT 2016-06-17 00:34:00+00:00 62.6 for DLH 2016-06-17 00:25:00+00:00\n",
      "using DYT 2016-06-17 00:34:00+00:00 62.6 for DLH 2016-06-17 00:30:00+00:00\n",
      "using DYT 2016-06-17 00:53:00+00:00 62.6 for DLH 2016-06-17 00:50:00+00:00\n",
      "using DYT 2016-06-17 01:14:00+00:00 60.8 for DLH 2016-06-17 01:05:00+00:00\n",
      "using DYT 2016-06-17 01:34:00+00:00 59.0 for DLH 2016-06-17 01:25:00+00:00\n",
      "using DYT 2016-06-17 01:53:00+00:00 59.0 for DLH 2016-06-17 01:50:00+00:00\n",
      "using DYT 2016-06-17 03:14:00+00:00 55.4 for DLH 2016-06-17 03:15:00+00:00\n",
      "using DYT 2016-06-17 03:33:00+00:00 55.4 for DLH 2016-06-17 03:25:00+00:00\n",
      "using DYT 2016-06-17 03:54:00+00:00 55.4 for DLH 2016-06-17 03:55:00+00:00\n",
      "using DYT 2016-06-17 04:14:00+00:00 55.4 for DLH 2016-06-17 04:15:00+00:00\n",
      "using DYT 2016-06-17 04:33:00+00:00 55.4 for DLH 2016-06-17 04:35:00+00:00\n",
      "using DYT 2016-06-17 04:54:00+00:00 55.4 for DLH 2016-06-17 04:45:00+00:00\n",
      "using DYT 2016-06-17 05:14:00+00:00 55.4 for DLH 2016-06-17 05:05:00+00:00\n",
      "using DYT 2016-06-17 05:14:00+00:00 55.4 for DLH 2016-06-17 05:15:00+00:00\n",
      "using DYT 2016-06-17 09:34:00+00:00 53.6 for DLH 2016-06-17 09:25:00+00:00\n",
      "using DYT 2016-06-17 09:54:00+00:00 53.6 for DLH 2016-06-17 09:55:00+00:00\n",
      "using DYT 2016-06-17 09:54:00+00:00 53.6 for DLH 2016-06-17 10:00:00+00:00\n",
      "using DYT 2016-06-17 10:13:00+00:00 53.6 for DLH 2016-06-17 10:15:00+00:00\n",
      "using DYT 2016-06-17 10:34:00+00:00 53.6 for DLH 2016-06-17 10:35:00+00:00\n",
      "using DYT 2016-06-17 10:53:00+00:00 53.6 for DLH 2016-06-17 10:55:00+00:00\n",
      "using DYT 2016-06-17 12:34:00+00:00 53.6 for DLH 2016-06-17 12:25:00+00:00\n",
      "using DYT 2016-06-17 12:34:00+00:00 53.6 for DLH 2016-06-17 12:30:00+00:00\n",
      "using DYT 2016-06-17 12:53:00+00:00 53.6 for DLH 2016-06-17 12:45:00+00:00\n",
      "using DYT 2016-06-17 13:14:00+00:00 55.4 for DLH 2016-06-17 13:05:00+00:00\n",
      "using DYT 2016-06-17 13:14:00+00:00 55.4 for DLH 2016-06-17 13:15:00+00:00\n",
      "using DYT 2016-06-17 13:34:00+00:00 55.4 for DLH 2016-06-17 13:25:00+00:00\n",
      "using DLH 2016-06-17 13:55:00+00:00 66.02 for DLH 2016-06-17 13:40:00+00:00\n",
      "using DYT 2016-06-17 16:14:00+00:00 55.4 for DLH 2016-06-17 16:05:00+00:00\n",
      "using DYT 2016-06-17 16:34:00+00:00 57.2 for DLH 2016-06-17 16:25:00+00:00\n",
      "using DYT 2016-06-17 18:33:00+00:00 60.8 for DLH 2016-06-17 18:25:00+00:00\n",
      "using DYT 2016-06-17 18:54:00+00:00 59.0 for DLH 2016-06-17 18:55:00+00:00\n",
      "using DYT 2016-06-17 21:54:00+00:00 66.2 for DLH 2016-06-17 21:45:00+00:00\n",
      "using DYT 2016-06-17 22:54:00+00:00 64.4 for DLH 2016-06-17 23:00:00+00:00\n",
      "using DYT 2016-06-17 23:14:00+00:00 64.4 for DLH 2016-06-17 23:25:00+00:00\n",
      "using DYT 2016-06-17 23:14:00+00:00 64.4 for DLH 2016-06-17 23:30:00+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-16 04:05:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>48.2</td>\n",
       "      <td>2016-06-16 04:05:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 04:15:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-06-16 04:15:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 04:35:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-06-16 04:35:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 04:45:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-06-16 04:45:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-16 04:55:00+00:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2016-06-16 04:55:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station  tmpf                      time\n",
       "valid                                                            \n",
       "2016-06-16 04:05:00+00:00     DLH  48.2 2016-06-16 04:05:00+00:00\n",
       "2016-06-16 04:15:00+00:00     DLH  50.0 2016-06-16 04:15:00+00:00\n",
       "2016-06-16 04:35:00+00:00     DLH  50.0 2016-06-16 04:35:00+00:00\n",
       "2016-06-16 04:45:00+00:00     DLH  50.0 2016-06-16 04:45:00+00:00\n",
       "2016-06-16 04:55:00+00:00     DLH  50.0 2016-06-16 04:55:00+00:00"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_data import ASOS\n",
    "asos = ASOS()\n",
    "dlh_df = asos.get_station_df('DLH', datetime(2016, 6, 16), datetime(2016, 6, 18))\n",
    "dlh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [station, tmpf, time]\n",
       "Index: []"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = dlh_df[pd.isna(dlh_df['tmpf'])]\n",
    "missing.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a temperature observation for each hour, since that is how the MISO MTLF is reported. Our initial approach will be to simply drop all missing observations, then choose the observation that is closest in time to the top of the hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dates = pd.date_range(start = first_hour, end = last_hour)\n",
    "observation_hours = [d.replace(hour = h) for d in observation_dates for h in range(0, 24)]\n",
    "\n",
    "def build_hourly_df(zone, state, station):\n",
    "    w = pd.read_parquet(download_file_path(zone, state, station))\n",
    "    df = w[w['tmpf'] != 'M'].copy()\n",
    "    df['valid'] = pd.to_datetime(df['valid'], utc=True)\n",
    "    numeric_cols = ['tmpf', 'lat', 'lon']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, axis=1)\n",
    "    df = df.drop(columns=['feel'])\n",
    "    idx = df.drop_duplicates('valid').set_index('valid').index.get_indexer(observation_hours, method='nearest')\n",
    "    df = df.iloc[idx]\n",
    "    df.loc[: , 'valid'] = df['valid'].dt.round(freq='H')\n",
    "    return df.drop_duplicates('valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = do_parallel(build_hourly_df)\n",
    "zonal_weather_data = {}\n",
    "for zone in zones:\n",
    "    zonal_weather_data[zone] = pd.concat(dfs[zone], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP observation count 59898\n",
      "RST observation count 59820\n",
      "DLH observation count 49334\n",
      "FAR observation count 59806\n",
      "BIS observation count 59792\n",
      "GFK observation count 59780\n",
      "ABR observation count 59714\n",
      "LSE observation count 59456\n",
      "SFY observation count 57519\n",
      "Required observations 60024\n"
     ]
    }
   ],
   "source": [
    "df = zonal_weather_data[1]\n",
    "for station in pd.unique(zonal_weather_data[1]['station']):\n",
    "    count = df[df['station'] == station].shape[0]\n",
    "    print(f'{station} observation count {count}')\n",
    "print(f'Required observations {len(observation_hours)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-08-22    24\n",
       "2020-10-30    23\n",
       "2020-09-23    22\n",
       "2018-09-12    21\n",
       "2021-05-02    21\n",
       "2018-08-22    20\n",
       "2020-10-25    19\n",
       "2021-05-03    18\n",
       "2018-04-25    17\n",
       "2019-07-07    17\n",
       "2018-06-20    17\n",
       "2018-05-14    17\n",
       "2018-05-07    17\n",
       "2018-07-30    17\n",
       "2018-05-10    17\n",
       "2018-07-14    17\n",
       "2020-07-20    16\n",
       "2018-07-06    16\n",
       "2019-03-25    16\n",
       "2018-03-22    16\n",
       "2018-07-11    16\n",
       "2018-03-21    16\n",
       "2018-07-13    16\n",
       "2020-02-06    16\n",
       "2019-04-27    16\n",
       "2018-07-17    16\n",
       "2019-06-13    16\n",
       "2018-03-17    16\n",
       "2018-03-16    16\n",
       "2018-07-05    16\n",
       "2018-03-13    16\n",
       "2018-07-23    16\n",
       "2018-07-24    16\n",
       "2018-07-27    16\n",
       "2018-03-09    16\n",
       "2018-03-14    16\n",
       "2018-06-19    16\n",
       "2019-06-20    16\n",
       "2019-07-16    16\n",
       "2018-05-11    16\n",
       "2018-05-12    16\n",
       "2018-05-13    16\n",
       "2019-07-31    16\n",
       "2018-05-15    16\n",
       "2018-05-06    16\n",
       "2018-05-18    16\n",
       "2018-05-05    16\n",
       "2018-05-20    16\n",
       "2018-05-22    16\n",
       "2019-07-13    16\n",
       "Name: Hours, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(df[df['station'] == 'DLH'], pd.DataFrame(observation_hours, columns=['Hours']), how='right', left_on='valid', right_on='Hours')\n",
    "merged[merged['station'].isna()]['Hours'].apply(lambda h: h.date).value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are entire days missing in the observations. We need to try to obtain observations from nearby stations to fill in the lacunae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 valid sites for MN\n",
      "Pandas(Index=0, elevation=367.0, sname='AITKIN NDB', time_domain='(1991-Now)', state='MN', country='US', climate_site='MN0059', wfo='DLH', tzname='America/Chicago', ncdc81='USC00210059', ncei91='USC00210059', ugc_county='MNC001', ugc_zone='MNZ036', county='Aitkin', sid='AIT', latlon=(46.5484, -93.6768), distance=73.35199477929798)\n"
     ]
    }
   ],
   "source": [
    "hour = merged[merged['station'].isna()].iloc[0]['Hours']\n",
    "from weather_data import get_nearest_observation, get_session\n",
    "tmpf = get_nearest_observation('DLH', 'MN', hour, get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\code\\mml\\01_obtain_data.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/code/mml/01_obtain_data.ipynb#ch0000017?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from weather_data import get_stations, get_session\n",
    "duluth = pd.read_parquet(download_file_path(1, 'MN', 'DLH'))\n",
    "stations_raw = get_stations('MN', 2015, get_session('https://'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort stations MN by closest to another station\n",
    "from geopy import distance\n",
    "dlh = stations_MN_df[stations_MN_df['sid'] == 'DLH'].iloc[0]['latlon']\n",
    "stations_MN_df['distance_from_DLH'] = stations_MN_df['latlon'].apply(lambda c: distance.distance(dlh, c).mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_MN_df.sort_values(['distance_from_DLH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.distance(dlh_latlon, dlh_latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Regional MTLF and Actual Load for each Observation Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_al_data import \n",
    "\n",
    "Path(\"./data/mtlf\").mkdir(exist_ok=True)\n",
    "forecast_output_dir = './data/mtlf'\n",
    "# the actuals aren't available until the next day\n",
    "actuals = get_daily_rf_al_df(first_hour, last_hour + timedelta(days=2.0), forecast_output_dir)\n",
    "actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize Features with Actuals\n",
    "\n",
    "There are a number of lacunae in the weather observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktime_idx(row): \n",
    "    return datetime.combine(row['Market Day'].date(), time(row['HourEnding'] - 1), timezone(timedelta(hours = -5)))\n",
    "\n",
    "actuals['time_idx'] = actuals.apply(mktime_idx, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.to_parquet('./data/actuals_mtlf.parquet')\n",
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.pivot(index='valid', columns='station', values='tmpf').dropna()\n",
    "data = p.join(actuals.set_index('time_idx'), how='inner')\n",
    "\n",
    "(n, _) = data.shape\n",
    "(num_weather_observations, _) = df.groupby('valid').count().shape\n",
    "(num_load_observations, _) = actuals.shape\n",
    "(num_weather_observations, num_load_observations, len(observation_hours), n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Business Hours\n",
    "\n",
    "Can we improve the performance of the model by introducing business hours into the feature set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay, BusinessHour\n",
    "\n",
    "federal_business_days = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "bh = BusinessHour()\n",
    "def is_biz_hour(d):\n",
    "    return federal_business_days.is_on_offset(d) and bh.is_on_offset(d)\n",
    "data['IsBusinessHour'] = data.index.to_series().apply(lambda d: 1 if is_biz_hour(d) else 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76a2b364cc0264c10adfbdfe3b5ba02e67c79fb140c1f3503657a619a8cf93d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data\n",
    "\n",
    "In this notebook we perform the following steps:\n",
    "* Establish the first hour of the dataset\n",
    "* For the first month,\n",
    "  * Obtain a list of available stations by state\n",
    "  * Obtain temperature observations from weather stations in the MISO footprint\n",
    "    * Stations are organized into MISO regions by state boundaries\n",
    "    * Stations are predominantly clustered in population centers, making many observation redundant\n",
    "    * There are many lacunae in some stations\n",
    "  * Obtain the actual hourly MISO Load data and historical Medium-Term Load Forecasts (MTLF)\n",
    "  * Join Load and MTLF data with weather observations to complete the raw data\n",
    "  * Persist the data and demonstrate use of dataset wrapper class\n",
    "* Update the dataset to the current day\n",
    "* Identify and mitigate lacunae\n",
    "* Publish the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from weather_data import prevailing_time as est\n",
    "\n",
    "# beginning of MISO's historical records that include the southern region (zones 8-10)\n",
    "# five hours weather data was lost for 2015-06-17\n",
    "first_hour = est(2015, 6, 18, 4)\n",
    "\n",
    "# latest date with actual load data available is\n",
    "# l = date.today() - timedelta(days=2)\n",
    "# last_hour = est(l.year, l.month, l.day, 23)\n",
    "# instead, fix the date for repeatbility\n",
    "last_hour = est(2022, 4, 22, 23)\n",
    "\n",
    "test_split = last_hour - timedelta(days=364, hours=23)\n",
    "validation_split = test_split - timedelta(days=365)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Weather Data for Zones\n",
    "\n",
    "[Iowa State ASOS Network Downloads](https://mesonet.agron.iastate.edu/request/download.phtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_data import ASOS\n",
    "from pathlib import Path\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "\n",
    "zones = { 1 : {'MN': ['MSP',  # Minneapolis / St. Paul (STP)\n",
    "                      'RST',  # Rochester\n",
    "                      'DYT'], # Duluth\n",
    "               'ND': ['FAR',  # Fargo\n",
    "                      'BIS',  # Bismarck\n",
    "                      'GFK'], # Grand Forks\n",
    "               'SD': ['ABR'], # Aberdeen\n",
    "               'WI': ['LSE'], # La Crosse\n",
    "               'IL': ['SFY']  # Savanna \n",
    "              },\n",
    "          2 : {'WI': ['MSN', 'MKE', 'EAU', 'GRB'],\n",
    "               'MI': ['ANJ', 'SAW', 'IWD']},\n",
    "          3 : {'IA': ['DSM', 'CID', 'DVN', 'SUX', 'ALO', 'MCW']}\n",
    "        }\n",
    "\n",
    "def download_file_path(zone, state, station):\n",
    "    zone_data = f\"./data/zone_{zone}\"\n",
    "    Path(zone_data).mkdir(exist_ok=True)\n",
    "    return f'{zone_data}/{state}_{station}.parquet'\n",
    "\n",
    "def download_station(zone, state, station):\n",
    "    path = download_file_path(zone, state, station) \n",
    "    if isfile(path):\n",
    "        return pd.read_parquet(path)\n",
    "\n",
    "    asos = ASOS()\n",
    "\n",
    "    station = asos.get_station_df(station, first_hour, last_hour)\n",
    "    if station is None:\n",
    "        print(f'Retrieve {station} failed')\n",
    "        return None\n",
    "    return station.to_parquet(path)\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "def do_parallel(func):\n",
    "    parallel = Parallel(n_jobs=cpu_count())\n",
    "    result = {}\n",
    "    for zone in zones:\n",
    "        stations = [(state, station) for state in zones[zone].keys() for station in zones[zone][state]]\n",
    "        result[zone] = parallel(delayed(func)(zone, state, station) for (state, station) in stations)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = do_parallel(download_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained raw weather observations at various intervals, usually 15 minutes, but there is a lot of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>feel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:00</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:15</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:20</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 17:35</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2016-04-30 18:00</td>\n",
       "      <td>M</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     station             valid tmpf      lat      lon feel\n",
       "9559     MSP  2016-04-30 17:00    M  44.8854 -93.2313    M\n",
       "9560     MSP  2016-04-30 17:15    M  44.8854 -93.2313    M\n",
       "9561     MSP  2016-04-30 17:20    M  44.8854 -93.2313    M\n",
       "9562     MSP  2016-04-30 17:35    M  44.8854 -93.2313    M\n",
       "9564     MSP  2016-04-30 18:00    M  44.8854 -93.2313    M"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "for zone in zones:\n",
    "  for state in zones[zone]:\n",
    "      for station in zones[zone][state]:\n",
    "        raw_df = pd.concat([raw_df, pd.read_parquet(download_file_path(zone, state, station))])\n",
    "raw_df[raw_df['tmpf'] == 'M'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880084, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[raw_df['tmpf'] == 'M'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>feel</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 00:53</td>\n",
       "      <td>68.00</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>68.00</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 01:53</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:27</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:48</td>\n",
       "      <td>66.20</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.20</td>\n",
       "      <td>66.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSP</td>\n",
       "      <td>2015-06-18 02:53</td>\n",
       "      <td>66.92</td>\n",
       "      <td>44.8854</td>\n",
       "      <td>-93.2313</td>\n",
       "      <td>66.92</td>\n",
       "      <td>66.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station             valid   tmpf      lat      lon   feel   temp\n",
       "0     MSP  2015-06-18 00:53  68.00  44.8854 -93.2313  68.00  68.00\n",
       "1     MSP  2015-06-18 01:53  66.92  44.8854 -93.2313  66.92  66.92\n",
       "2     MSP  2015-06-18 02:27  66.92  44.8854 -93.2313  66.92  66.92\n",
       "3     MSP  2015-06-18 02:48  66.20  44.8854 -93.2313  66.20  66.20\n",
       "4     MSP  2015-06-18 02:53  66.92  44.8854 -93.2313  66.92  66.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['temp'] = pd.to_numeric(raw_df['tmpf'], errors='coerce')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10880084, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_temps = raw_df[pd.isna(raw_df['temp'])]\n",
    "missing_temps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-18 14:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 19:00:00+00:00</td>\n",
       "      <td>80.970473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 15:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 19:55:00+00:00</td>\n",
       "      <td>82.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 16:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 21:00:00+00:00</td>\n",
       "      <td>80.063491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 17:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 21:55:00+00:00</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 18:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 22:55:00+00:00</td>\n",
       "      <td>78.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 19:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 23:55:00+00:00</td>\n",
       "      <td>78.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 20:00:00-05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>78.468646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 21:00:00-05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>81.101770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 22:00:00-05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>85.987049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:00:00-05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>93.644189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station          observation_time       temp\n",
       "hour                                                                  \n",
       "2016-06-18 14:00:00-05:00     DLH 2016-06-18 19:00:00+00:00  80.970473\n",
       "2016-06-18 15:00:00-05:00     DLH 2016-06-18 19:55:00+00:00  82.940000\n",
       "2016-06-18 16:00:00-05:00     DLH 2016-06-18 21:00:00+00:00  80.063491\n",
       "2016-06-18 17:00:00-05:00     DLH 2016-06-18 21:55:00+00:00  77.000000\n",
       "2016-06-18 18:00:00-05:00     DLH 2016-06-18 22:55:00+00:00  78.080000\n",
       "2016-06-18 19:00:00-05:00     DLH 2016-06-18 23:55:00+00:00  78.080000\n",
       "2016-06-18 20:00:00-05:00     NaN                       NaT  78.468646\n",
       "2016-06-18 21:00:00-05:00     NaN                       NaT  81.101770\n",
       "2016-06-18 22:00:00-05:00     NaN                       NaT  85.987049\n",
       "2016-06-18 23:00:00-05:00     NaN                       NaT  93.644189"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlh_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?data=tmpf&data=feel&tz=Etc/UTC&format=comma&latlon=yes&year1=2016&month1=6&day1=15&year2=2016&month2=6&day2=21&station=DLH\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-18 18:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-18 22:55:00+00:00</td>\n",
       "      <td>78.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 19:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 00:00:00+00:00</td>\n",
       "      <td>76.343357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 20:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 01:00:00+00:00</td>\n",
       "      <td>74.984660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 21:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 02:00:00+00:00</td>\n",
       "      <td>73.637452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 22:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 03:05:00+00:00</td>\n",
       "      <td>72.345319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-18 23:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 04:00:00+00:00</td>\n",
       "      <td>71.151849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 00:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 04:55:00+00:00</td>\n",
       "      <td>69.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 01:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 05:55:00+00:00</td>\n",
       "      <td>69.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 02:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 06:55:00+00:00</td>\n",
       "      <td>69.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-19 03:00:00-05:00</th>\n",
       "      <td>DLH</td>\n",
       "      <td>2016-06-19 08:05:00+00:00</td>\n",
       "      <td>68.209900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          station          observation_time       temp\n",
       "hour                                                                  \n",
       "2016-06-18 18:00:00-05:00     DLH 2016-06-18 22:55:00+00:00  78.080000\n",
       "2016-06-18 19:00:00-05:00     DLH 2016-06-19 00:00:00+00:00  76.343357\n",
       "2016-06-18 20:00:00-05:00     DLH 2016-06-19 01:00:00+00:00  74.984660\n",
       "2016-06-18 21:00:00-05:00     DLH 2016-06-19 02:00:00+00:00  73.637452\n",
       "2016-06-18 22:00:00-05:00     DLH 2016-06-19 03:05:00+00:00  72.345319\n",
       "2016-06-18 23:00:00-05:00     DLH 2016-06-19 04:00:00+00:00  71.151849\n",
       "2016-06-19 00:00:00-05:00     DLH 2016-06-19 04:55:00+00:00  69.980000\n",
       "2016-06-19 01:00:00-05:00     DLH 2016-06-19 05:55:00+00:00  69.980000\n",
       "2016-06-19 02:00:00-05:00     DLH 2016-06-19 06:55:00+00:00  69.080000\n",
       "2016-06-19 03:00:00-05:00     DLH 2016-06-19 08:05:00+00:00  68.209900"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weather_data import ASOS\n",
    "asos = ASOS()\n",
    "dlh_df = asos.get_station_df('DLH', est(2016, 6, 16, 0), est(2016, 6, 19, 3))\n",
    "dlh_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 1, 1, 5, 0, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est(2021, 1, 1, 0).astimezone(timezone.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a temperature observation for each hour, since that is how the MISO MTLF is reported. Our initial approach will be to simply drop all missing observations, then choose the observation that is closest in time to the top of the hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_dates = pd.date_range(start = first_hour, end = last_hour)\n",
    "observation_hours = [d.replace(hour = h) for d in observation_dates for h in range(0, 24)]\n",
    "\n",
    "def build_hourly_df(zone, state, station):\n",
    "    w = pd.read_parquet(download_file_path(zone, state, station))\n",
    "    df = w[w['tmpf'] != 'M'].copy()\n",
    "    df['valid'] = pd.to_datetime(df['valid'], utc=True)\n",
    "    numeric_cols = ['tmpf', 'lat', 'lon']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, axis=1)\n",
    "    df = df.drop(columns=['feel'])\n",
    "    idx = df.drop_duplicates('valid').set_index('valid').index.get_indexer(observation_hours, method='nearest')\n",
    "    df = df.iloc[idx]\n",
    "    df.loc[: , 'valid'] = df['valid'].dt.round(freq='H')\n",
    "    return df.drop_duplicates('valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = do_parallel(build_hourly_df)\n",
    "zonal_weather_data = {}\n",
    "for zone in zones:\n",
    "    zonal_weather_data[zone] = pd.concat(dfs[zone], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP observation count 59898\n",
      "RST observation count 59820\n",
      "DLH observation count 49334\n",
      "FAR observation count 59806\n",
      "BIS observation count 59792\n",
      "GFK observation count 59780\n",
      "ABR observation count 59714\n",
      "LSE observation count 59456\n",
      "SFY observation count 57519\n",
      "Required observations 60024\n"
     ]
    }
   ],
   "source": [
    "df = zonal_weather_data[1]\n",
    "for station in pd.unique(zonal_weather_data[1]['station']):\n",
    "    count = df[df['station'] == station].shape[0]\n",
    "    print(f'{station} observation count {count}')\n",
    "print(f'Required observations {len(observation_hours)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-08-22    24\n",
       "2020-10-30    23\n",
       "2020-09-23    22\n",
       "2018-09-12    21\n",
       "2021-05-02    21\n",
       "2018-08-22    20\n",
       "2020-10-25    19\n",
       "2021-05-03    18\n",
       "2018-04-25    17\n",
       "2019-07-07    17\n",
       "2018-06-20    17\n",
       "2018-05-14    17\n",
       "2018-05-07    17\n",
       "2018-07-30    17\n",
       "2018-05-10    17\n",
       "2018-07-14    17\n",
       "2020-07-20    16\n",
       "2018-07-06    16\n",
       "2019-03-25    16\n",
       "2018-03-22    16\n",
       "2018-07-11    16\n",
       "2018-03-21    16\n",
       "2018-07-13    16\n",
       "2020-02-06    16\n",
       "2019-04-27    16\n",
       "2018-07-17    16\n",
       "2019-06-13    16\n",
       "2018-03-17    16\n",
       "2018-03-16    16\n",
       "2018-07-05    16\n",
       "2018-03-13    16\n",
       "2018-07-23    16\n",
       "2018-07-24    16\n",
       "2018-07-27    16\n",
       "2018-03-09    16\n",
       "2018-03-14    16\n",
       "2018-06-19    16\n",
       "2019-06-20    16\n",
       "2019-07-16    16\n",
       "2018-05-11    16\n",
       "2018-05-12    16\n",
       "2018-05-13    16\n",
       "2019-07-31    16\n",
       "2018-05-15    16\n",
       "2018-05-06    16\n",
       "2018-05-18    16\n",
       "2018-05-05    16\n",
       "2018-05-20    16\n",
       "2018-05-22    16\n",
       "2019-07-13    16\n",
       "Name: Hours, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(df[df['station'] == 'DLH'], pd.DataFrame(observation_hours, columns=['Hours']), how='right', left_on='valid', right_on='Hours')\n",
    "merged[merged['station'].isna()]['Hours'].apply(lambda h: h.date).value_counts()[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are entire days missing in the observations. We need to try to obtain observations from nearby stations to fill in the lacunae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 valid sites for MN\n",
      "Pandas(Index=0, elevation=367.0, sname='AITKIN NDB', time_domain='(1991-Now)', state='MN', country='US', climate_site='MN0059', wfo='DLH', tzname='America/Chicago', ncdc81='USC00210059', ncei91='USC00210059', ugc_county='MNC001', ugc_zone='MNZ036', county='Aitkin', sid='AIT', latlon=(46.5484, -93.6768), distance=73.35199477929798)\n"
     ]
    }
   ],
   "source": [
    "hour = merged[merged['station'].isna()].iloc[0]['Hours']\n",
    "from weather_data import get_nearest_observation, get_session\n",
    "tmpf = get_nearest_observation('DLH', 'MN', hour, get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chris\\code\\mml\\01_obtain_data.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chris/code/mml/01_obtain_data.ipynb#ch0000017?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from weather_data import get_stations, get_session\n",
    "duluth = pd.read_parquet(download_file_path(1, 'MN', 'DLH'))\n",
    "stations_raw = get_stations('MN', 2015, get_session('https://'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort stations MN by closest to another station\n",
    "from geopy import distance\n",
    "dlh = stations_MN_df[stations_MN_df['sid'] == 'DLH'].iloc[0]['latlon']\n",
    "stations_MN_df['distance_from_DLH'] = stations_MN_df['latlon'].apply(lambda c: distance.distance(dlh, c).mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_MN_df.sort_values(['distance_from_DLH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.distance(dlh_latlon, dlh_latlon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Regional MTLF and Actual Load for each Observation Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_al_data import \n",
    "\n",
    "Path(\"./data/mtlf\").mkdir(exist_ok=True)\n",
    "forecast_output_dir = './data/mtlf'\n",
    "# the actuals aren't available until the next day\n",
    "actuals = get_daily_rf_al_df(first_hour, last_hour + timedelta(days=2.0), forecast_output_dir)\n",
    "actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonize Features with Actuals\n",
    "\n",
    "There are a number of lacunae in the weather observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mktime_idx(row): \n",
    "    return datetime.combine(row['Market Day'].date(), time(row['HourEnding'] - 1), timezone(timedelta(hours = -5)))\n",
    "\n",
    "actuals['time_idx'] = actuals.apply(mktime_idx, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals.to_parquet('./data/actuals_mtlf.parquet')\n",
    "actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.pivot(index='valid', columns='station', values='tmpf').dropna()\n",
    "data = p.join(actuals.set_index('time_idx'), how='inner')\n",
    "\n",
    "(n, _) = data.shape\n",
    "(num_weather_observations, _) = df.groupby('valid').count().shape\n",
    "(num_load_observations, _) = actuals.shape\n",
    "(num_weather_observations, num_load_observations, len(observation_hours), n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Business Hours\n",
    "\n",
    "Can we improve the performance of the model by introducing business hours into the feature set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay, BusinessHour\n",
    "\n",
    "federal_business_days = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "bh = BusinessHour()\n",
    "def is_biz_hour(d):\n",
    "    return federal_business_days.is_on_offset(d) and bh.is_on_offset(d)\n",
    "data['IsBusinessHour'] = data.index.to_series().apply(lambda d: 1 if is_biz_hour(d) else 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76a2b364cc0264c10adfbdfe3b5ba02e67c79fb140c1f3503657a619a8cf93d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
